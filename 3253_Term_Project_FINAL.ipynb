{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahaansshah/3253-083_Group9/blob/main/3253_Term_Project_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "\n",
        "class HousingDataProcessor:\n",
        "    \"\"\"\n",
        "    Class to process and prepare housing data for machine learning models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, file_path):\n",
        "        \"\"\"\n",
        "        Initializes the HousingDataProcessor with the path to the JSON data file.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        file_path : str\n",
        "            The path to the JSON data file.\n",
        "        \"\"\"\n",
        "        self.file_path = file_path\n",
        "        self.df = self.load_and_process_data()\n",
        "\n",
        "    def load_and_process_data(self):\n",
        "        \"\"\"\n",
        "        Loads the JSON data, flattens the nested structure, and performs initial data cleaning.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        pandas.DataFrame\n",
        "            The processed DataFrame.\n",
        "        \"\"\"\n",
        "        records = []\n",
        "        with open(self.file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    data = json.loads(line)\n",
        "                    record = data.get('data')\n",
        "                    if record is not None:\n",
        "                        features = {}\n",
        "                        for feature_group in record.get('features', []):\n",
        "                            for feature_category in feature_group.get('value', []):\n",
        "                                for feature in feature_category.get('value', []):\n",
        "                                    features[f\"{feature_group['name']}_{feature_category['name']}_{feature['name']}\"] = feature['value']\n",
        "\n",
        "                        record.update(features)\n",
        "                        record.pop('features', None)\n",
        "                        records.append(record)\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Skipping invalid JSON line: {line}\")\n",
        "\n",
        "        df = pd.DataFrame(records)\n",
        "        return df\n",
        "\n",
        "    def clean_data(self):\n",
        "        \"\"\"\n",
        "        Removes irrelevant columns, handles missing values, and prepares categorical features.\n",
        "        \"\"\"\n",
        "\n",
        "        # Inspect columns with missing data\n",
        "        self.inspect_missing_data()\n",
        "\n",
        "        # Clean up column names and keep only relevant columns\n",
        "        self.rationalize_columns()\n",
        "\n",
        "        # Normalize the values of the amenities columns\n",
        "        self.normalize_amenities()\n",
        "\n",
        "        # Calculate distance to lake\n",
        "        self.calculate_distance_to_lake()\n",
        "\n",
        "        # Extract square footage from description\n",
        "        self.extract_square_footage_from_description()\n",
        "\n",
        "        # Drop propertyType in 'FARM', 'Land', 'Other', 'Multi Family'\n",
        "        self.df = self.df[~self.df['propertyType'].isin(['FARM', 'Land', 'Other', 'Multi_Family'])]\n",
        "\n",
        "        # One-hot encode categorical features\n",
        "        self.one_hot_encode_categorical_features()\n",
        "\n",
        "        # Handle missing values (similar to your original code, but using methods)\n",
        "        self.handle_missing_values()\n",
        "\n",
        "\n",
        "    def inspect_missing_data(self):\n",
        "      # look up which fields contain a lot of missing data\n",
        "      missing_values = [col for col in self.df.columns if self.df[col].isnull().any()]\n",
        "      print('Number of columns with missing values:', len(missing_values), '\\n')\n",
        "\n",
        "      for col in missing_values:\n",
        "        print(col, round(self.df[col].isnull().mean(), 3)*100, '% missing values')\n",
        "\n",
        "      print('\\n***************\\n\\n')\n",
        "\n",
        "\n",
        "    def rationalize_columns(self):\n",
        "        # Clean up column names\n",
        "        self.df.columns = self.df.columns.str.replace(r' +', '_', regex=True)\n",
        "\n",
        "        # Keep only relevant columns\n",
        "        columns_to_keep = ['latitude', 'listPrice', 'longitude', 'lotSize', 'numBathrooms',\n",
        "       'numBedrooms', 'parking', 'propertyType', 'yearBuilt', 'garage',\n",
        "       'Amenities_Utilities_Heating_Cooling_Cooling',\n",
        "       'Amenities_Utilities_Heating_Cooling_Heat_Source']\n",
        "        self.df = self.df[columns_to_keep]\n",
        "\n",
        "\n",
        "    def normalize_amenities(self):\n",
        "        \"\"\"\n",
        "        Categorical variables levels cleanup\n",
        "        \"\"\"\n",
        "        self.df['Amenities_Utilities_Heating_Cooling_Cooling'] = self.df['Amenities_Utilities_Heating_Cooling_Cooling'].str.replace(r'Ductless.*|.*Central .*', 'Y', regex=True)\n",
        "        self.df['Amenities_Utilities_Heating_Cooling_Cooling'] = self.df['Amenities_Utilities_Heating_Cooling_Cooling'].str.replace(r'^(?!.*Y).*', 'N', regex=True)\n",
        "        self.df['Amenities_Utilities_Heating_Cooling_Heat_Source'] = self.df['Amenities_Utilities_Heating_Cooling_Heat_Source'].str.replace(r'Electric.*', 'Electric', regex=True)\n",
        "        self.df['Amenities_Utilities_Heating_Cooling_Heat_Source'] = self.df['Amenities_Utilities_Heating_Cooling_Heat_Source'].str.replace(r'Natural gas.*', 'Gas', regex=True)\n",
        "        self.df['Amenities_Utilities_Heating_Cooling_Heat_Source'] = self.df['Amenities_Utilities_Heating_Cooling_Heat_Source'].str.replace(r'^(?!Electric|Gas).*', 'Other', regex=True)\n",
        "\n",
        "\n",
        "    def calculate_distance_to_lake(self):\n",
        "        \"\"\"\n",
        "        Calculates the minimum distance to lake points for each property.\n",
        "        \"\"\"\n",
        "        def distance(origin, destination):\n",
        "            \"\"\"\n",
        "            Calculate the Haversine distance.\n",
        "\n",
        "            Parameters:\n",
        "            ----------\n",
        "            origin : tuple of float\n",
        "                (latitude, longitude)\n",
        "            destination : tuple of float\n",
        "                (latitude, longitude)\n",
        "\n",
        "            Returns:\n",
        "            -------\n",
        "            distance_in_km : float\n",
        "            \"\"\"\n",
        "            lat1, lon1 = origin\n",
        "            lat2, lon2 = destination\n",
        "            radius = 6371  # km\n",
        "\n",
        "            dlat = math.radians(lat2 - lat1)\n",
        "            dlon = math.radians(lon2 - lon1)\n",
        "            a = (math.sin(dlat / 2) * math.sin(dlat / 2) +\n",
        "                 math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) *\n",
        "                 math.sin(dlon / 2) * math.sin(dlon / 2))\n",
        "            c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
        "            d = radius * c\n",
        "\n",
        "            return d\n",
        "\n",
        "        shorepoints = [(43.337573, -79.769493), (43.325047, -79.792023), (43.346755, -79.758282), (43.352226, -79.751185),\n",
        "              (43.362459, -79.737418), (43.366887, -79.729100), (43.385790, -79.712277), (43.399670, -79.700950),\n",
        "              (43.419369, -79.683863), (43.451628, -79.654371), (43.467697, -79.640033), (43.486686, -79.617320),\n",
        "              (43.517525, -79.601415), (43.538370, -79.594686), (43.562755, -79.564711), (43.576052, -79.543607),\n",
        "              (43.594663, -79.503232), (43.625224, -79.478151), (43.630317, -79.433801), (43.632973, -79.407191),\n",
        "              (43.272289, -79.919314), (43.276725, -79.860298), (43.271462, -79.833200), (43.251221, -79.757855),\n",
        "          ]\n",
        "\n",
        "        distances = []\n",
        "        for id, row in self.df.iterrows():\n",
        "            mindist = distance((row[\"latitude\"], row[\"longitude\"]), shorepoints[0])\n",
        "            for point in shorepoints:\n",
        "                dist = distance((row[\"latitude\"], row[\"longitude\"]), point)\n",
        "                if dist < mindist:\n",
        "                    mindist = dist\n",
        "            distances.append(mindist)\n",
        "        self.df.insert(len(self.df.iloc[0]), \"distance_to_lake\", distances)\n",
        "\n",
        "\n",
        "    def extract_square_footage_from_description(self):\n",
        "      \"\"\"\n",
        "      Extracts square footage from the 'description' column.\n",
        "      \"\"\"\n",
        "      \"\"\"\n",
        "      ## THIS CODE IS ONLY PRESENT TO SHOW HOW DATA WAS COLLECTED AND DOES NOT HAVE THE REQUIRED API KEY TO RUN\n",
        "      ## Completing the dataset by adding missing entries of square footage using the description which includes square footage (usually) and using the AzureAI chatbot to analyze text and return the square footage or None.\n",
        "\n",
        "      # Connection to openai chatbot\n",
        "      deployment_name = \"REDACTED\"\n",
        "      client = AzureOpenAI(\n",
        "          api_key= \"REDACTED\", ## I am not allowed to share this API key for legal reasons but it was used to message the Azure AI chatbot\n",
        "          api_version=\"2024-02-01\",\n",
        "          azure_endpoint = \"REDACTED\"\n",
        "          )\n",
        "\n",
        "      def message_chatbot(message, description):\n",
        "\n",
        "          # Uses the connecetion made to make a request to the Azure openai chatbot\n",
        "          response = client.chat.completions.create(\n",
        "              model=deployment_name,\n",
        "              temperature=0.7,\n",
        "              max_tokens=400,\n",
        "\n",
        "              # Both messages to be submitted\n",
        "              messages=[\n",
        "                  {\"role\": \"system\", \"content\": message},\n",
        "                  {\"role\": \"user\", \"content\": description}\n",
        "              ]\n",
        "          )\n",
        "          generated_text = response.choices[0].message.content\n",
        "\n",
        "          return (generated_text)\n",
        "\n",
        "      message = \"The following will be a description of a house, Please find the total square footage of the house and return it as a single number without any commas or measurements. Do not return any other text other than the number itself, without any math equations or explanations, just a number. If there is no square footage found return 'None'\"\n",
        "      sqfootage = []\n",
        "      for id, row in df_cleaned.iterrows():\n",
        "          if row[\"sqftTotalRaw\"] == 0 or row[\"sqftTotalRaw\"] == None:\n",
        "              sqfootage.append(message_chatbot(message, row[\"description\"]))\n",
        "          else:\n",
        "              sqfootage.append(row[\"sqftTotalRaw\"])\n",
        "      \"\"\"\n",
        "      ## Because the above code does not work without the API (and I am not allowed to put it here), this is what it wouldve generated, sorry for the hardcoding :( to be fair this isn't part of the assignment and was extra work\n",
        "      ## HARDCODING PRESENT DUE TO NOT HAVING THE API KEY\n",
        "      sqfootage = [\n",
        "      '1200',\n",
        "      'None', 'None', '600', '3993', '2816', 'None', '1350', '3180', '1075', '1824', '2980', 'None', '3262', '1000', '1191', '4487', 'None', 'None', '1108', 'None',\n",
        "      '2900', '5186', 'None', '1479', '4000', '3100', '950', 'None', '2500', '5246', 'None', 'None', '3214', '1400', 'None', '2000', '3537', 'None', '1800', '3284',\n",
        "      '1762', '4303', '4100', '1936', '1017', '2617', '9900', '1000', '79954', '613', '1950', 'None', '2500', 'None', '1800', '1088', '1911', '2159', '1700', '4367',\n",
        "      '5293', '1200', '1918', '986', '717', '2000', '1146', '6000', 'None', 'None', 'None', 'None', '3860', '6984', 'None', '3800', '715', 'None', '1990', '7476',\n",
        "      'None', '610', 'None', 'None', '711', '1351', '1617', 'None', 'None', 'None', 'None', '2000', 'None', 'None', 'None', 'None', '1161', 'None', '5000', '2595',\n",
        "      'None', '2702', 'None', 'None', 'None', '2018', '660', 'None', '6568', 'None', 'None', 'None', '1700', 'None', '3300', '3108', '2720', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', '1075', '2805', '4600', '3614', '2500', 'None', '1710', '1285', '4655', 'None', '2944', '4038', 'None', 'None', '3285', 'None',\n",
        "      '3800', '2150', 'None', '1900', 'None', 'None', '2000', 'None', '1535', '3124', 'None', '845', 'None', '3234', 'None', '1400', 'None', 'None', 'None', '995',\n",
        "      '3100', 'None', '3873', 'None', '3886', '3400', '1783', 'None', 'None', '1900', 'None', '1557', '1783', '2918', '1300', 'None', '946', '592', 'None', 'None',\n",
        "      'None', '715', 'None', '3680', '3610', 'None', 'None', '2857', '1850', '3262', 'None', 'None', '2440', '2077', 'None', '4000', '6127', '479', 'None', '2734',\n",
        "      '2791', 'None', 'None', '1462', 'None', 'None', 'None', '840', 'None', 'None', '6772', 'None', 'None', '4401', '3550', 'None', '756', 'None', '4423', '2250',\n",
        "      'None', 'None', 'None', '3718', 'None', '9907', 'None', 'None', 'None', '1250', 'None', 'None', 'None', 'None', 'None', '3081', '2953', 'None', '962', '1535',\n",
        "      'None', 'None', '1700', '6400', 'None', '1250', '7494', 'None', '500', 'None', '2159', 'None', 'None', 'None', 'None', '528', '2150', '2406', 'None', 'None',\n",
        "      'None', '3143', 'None', '2856', '1900', '2789', 'None', '2767', '3000', '4364', 'None', '3921', '4000', '4680', 'None', '6416', '3430', '8750', '1000', '7500',\n",
        "      '922', '1790', '2981', '1351', 'None', 'None', 'None', 'None', '3500', 'None', '4200', '3500', '2326', 'None', '3000', 'None', '1288', 'None', '1800', '1774',\n",
        "      'None', '2000', '2150', '1170', '1408', '1', 'None', '5000', 'None', '1050', 'None', '2700', '2720', '1000', '3200', 'None', 'None', '2820', 'None', 'None',\n",
        "      'None', '3200', '630', '3550', '1548', 'None', '1084', '8000', '1455', 'None', '6568', 'None', '5470', '2500', 'None', '3368', '820', 'None', 'None', '2041',\n",
        "      '735', '1762', '4303', '854', 'None', '3400', 'None', '855', 'None', 'None', 'None', 'None', 'None', 'None', '2946', '1079', '4400', '1408', 'None', '6424',\n",
        "      'None', 'None', 'None', '1990', 'None', 'None', '2210', '2593', '735', 'None', 'None', '4600', '730', '5922', '2000', 'None', '5883', 'None', '3000', '7400',\n",
        "      'None', '1943', '997', '1783', '1780', '2247', 'None', '3716', '2243', '6470', '854', '1413', 'None', 'None', 'None', '6220', 'None', '1411', '1428', '1258',\n",
        "      '1780', 'None', '1954', 'None', '700', '1400', '1200', '655', '2200', 'None', 'None', 'None', '2744', '3700', '1880', 'None', '6829', '1050', '1615', 'None',\n",
        "      'None', 'None', 'None', '774', '1577', 'None', 'None', 'None', 'None', '700', 'None', '5000', '714', '2300', '6100', 'None', 'None', '1264', '1119', 'None',\n",
        "      '5745', '4279', 'None', '3558', 'None', '4728', 'None', '1321', '4364', 'None', 'None', 'None', 'None', '2691', '1830', '4000', 'None', '972', '980', '3019',\n",
        "      'None', 'None', 'None', '7715', '586', '4482', '900', 'None', '3800', '4000', '3600', 'None', '4867', '1113', '943', '620', '1250', 'None', 'None', '2971',\n",
        "      '2816', '1200', '1630', 'None', 'None', 'None', '2900', 'None', '625', 'None', 'None', '3173', 'None', 'None', '3815', 'None', '2056', '1000', 'None', '3815',\n",
        "      'None', '3316', '5000', '4000', '972', 'None', 'None', 'None', '1948', '4200', 'None', 'None', 'None', '2065', 'None', 'None', '3653', '1188', '2321', 'None',\n",
        "      '1201', 'None', '5700', 'None', '4054', '2728', '2807', '2704', 'None', '1866', 'None', '1700', '1501', 'None', '3325', '3800', '2459', '933', '2026', '629',\n",
        "      'None', 'None', '2790', '4200', '3180', '650', '2479', '613', '3700', 'None', '1830', 'None', '3999', 'None', 'None', 'None', 'None', 'None', '3605', 'None',\n",
        "      'None', '4750', '1700', '1450', '3000', '916', 'None', '4597', 'None', 'None', 'None', 'None', 'None', 'None', '2000', 'None', 'None', 'None', '13400', '1700',\n",
        "      'None', '469', 'None', '9413', 'None', '3741', '830', '1290', 'None', 'None', 'None', '2677', 'None', 'None', 'None', 'None', 'None', '13400', 'None', 'None',\n",
        "      '5400', '2500', 'None', 'None', 'None', 'None', 'None', '2064', '3447', 'None', '830', 'None', '4000', 'None', '839', 'None', 'None', '3880', '1586', 'None',\n",
        "      '1650', 'None', 'None', 'None', 'None', '1800', 'None', 'None', 'None', '1100', '1300', 'None', 'None', 'None', 'None', 'None', '2768', 'None', 'None', 'None',\n",
        "      '1500', '1600', 'None', 'None', 'None', '827', 'None', 'None', 'None', 'None', 'None', 'None', '1480', 'None', 'None', 'None', 'None', '1186', '7700', '1400',\n",
        "      'None', 'None', '640', '988', 'None', 'None', 'None', '576', 'None', 'None', 'None', 'None', '1000', 'None', '1655', 'None', 'None', 'None', 'None', 'None',\n",
        "      '4000', 'None', 'None', '600', '3000', '9334', 'None', '1000', '1300', 'None', 'None', '2676', '1300', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', '1800', 'None', '784', '590', 'None', '3111', '608', 'None', 'None', 'None', 'None', 'None', '1405', '841', '1087', 'None', 'None', 'None', '1136',\n",
        "      'None', '1100', '1870', 'None', 'None', '2777', 'None', 'None', 'None', 'None', 'None', 'None', '400', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', '3000', 'None', 'None', 'None', '756', '821', '1347', 'None', 'None', '1150', 'None', 'None', '5500', 'None', 'None', '910', '1300', 'None', 'None',\n",
        "      '1655', 'None', 'None', '1350', '1575', '566', 'None', 'None', '800', 'None', '1100', '948', '1100', '1203', '1186', 'None', 'None', 'None', '1032', 'None',\n",
        "      'None', '9334', '4410', '1179', '965', 'None', 'None', 'None', 'None', 'None', '965', 'None', 'None', 'None', 'None', '2651', 'None', 'None', 'None', 'None',\n",
        "      '1275', 'None', 'None', 'None', 'None', 'None', 'None', '560', '691', 'None', '3500', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', '4300', 'None', 'None', '600', 'None', '1500', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '3000', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', 'None', '2924', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '2500', '723', 'None', '4126', '630', 'None', 'None', 'None', 'None', '800',\n",
        "      'None', 'None', 'None', '821', 'None', 'None', '562', 'None', 'None', 'None', '1685', '846', '3000', 'None', '1933', 'None', 'None', 'None', 'None', '5000',\n",
        "      '4400', 'None', 'None', 'None', 'None', '1100', '4760', '2986', '836', 'None', 'None', 'None', 'None', 'None', 'None', '560', '3638', '1136', 'None', 'None',\n",
        "      'None', 'None', '4000', 'None', '910', 'None', '982', '3282', 'None', 'None', '700', 'None', 'None', 'None', 'None', 'None', '3063', '3631', '2300', 'None',\n",
        "      'None', 'None', '723', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1050', '576', 'None', 'None', '940', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', '1370', 'None', '5500', '2636', 'None', '1138', 'None', '800', 'None', 'None', '1138', 'None', 'None', 'None', '716', 'None',\n",
        "      'None', 'None', 'None', '3705', '1360', '3296', 'None', 'None', 'None', 'None', 'None', 'None', '540', 'None', '1700', 'None', 'None', 'None', 'None', '562',\n",
        "      '953', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1500', 'None', 'None', '703', '4000', 'None', '2360', 'None', 'None',\n",
        "      '2020', '1347', 'None', 'None', 'None', '1084', 'None', '1100', 'None', 'None', 'None', 'None', '580', '1174', 'None', 'None', '982', 'None', 'None', '728',\n",
        "      'None', '810', '795', 'None', 'None', '810', 'None', 'None', '1690', 'None', 'None', '1625', 'None', '6500', '2500', 'None', 'None', '784', 'None', '3073',\n",
        "      'None', 'None', 'None', 'None', '756', '1032', '2000', 'None', 'None', 'None', 'None', 'None', '2300', 'None', '700', 'None', '2215', '1179', 'None', 'None',\n",
        "      'None', '630', '2300', '1290', '1000', '3000', '799', 'None', 'None', 'None', '2064', 'None', 'None', '4400', 'None', 'None', '1343', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', '1150', '562', '566', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1200', '875', 'None', 'None', '948', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', 'None', '1041', '1655', 'None', 'None', 'None', 'None', 'None', '1300', 'None', 'None', 'None', 'None', 'None',\n",
        "      '2070', '562', 'None', 'None', 'None', '5000', 'None', 'None', '515', 'None', '2050', '2100', 'None', 'None', 'None', 'None', '1626', 'None', 'None', 'None',\n",
        "      'None', 'None', '846', 'None', 'None', 'None', '5000', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      '3500', '4075', 'None', 'None', 'None', '1025', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '800', 'None', 'None', 'None', '563', '2000', '1483',\n",
        "      'None', 'None', 'None', 'None', '1405', 'None', 'None', 'None', '1100', 'None', '2197', 'None', 'None', '2677', 'None', '1338', 'None', '1897', 'None', 'None',\n",
        "      '1405', '2200', 'None', '830', 'None', '1483', 'None', 'None', 'None', '1157', 'None', 'None', '1369', 'None', 'None', '2622', '1000', '1010', 'None', '2194',\n",
        "      'None', 'None', '4000', 'None', 'None', '1549', 'None', '3000', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', '2100', 'None', 'None', 'None', 'None', 'None', '993', 'None', '785', '2309', 'None', '1132', '1447', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', '1416', 'None', 'None', 'None', '2600', 'None', 'None', 'None', '984', 'None', 'None', 'None', 'None', 'None', '1383', 'None', 'None',\n",
        "      'None', 'None', '1141', 'None', '0000', '3297', '1358', 'None', '3000', '3092', 'None', 'None', 'None', 'None', 'None', 'None', '1860', '1158', '1772', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', '1500', '1483', 'None', 'None', 'None', 'None', 'None', 'None', '1900', '1313', 'None', 'None', 'None', 'None', 'None',\n",
        "      '1300', 'None', '1441', '3092', '1000', '2500', 'None', 'None', '2350', '2651', 'None', 'None', 'None', 'None', '1589', 'None', '1736', 'None', 'None', 'None',\n",
        "      '2812', '1324', 'None', 'None', '4409', '1072', 'None', 'None', 'None', 'None', '3400', '2700', '2158', 'None', '1185', '2252', 'None', 'None', 'None', '1615',\n",
        "      'None', '879', '2615', 'None', '1978', 'None', '1000', '998', 'None', 'None', 'None', '1897', 'None', '1608', 'None', '1500', 'None', '700', 'None', 'None',\n",
        "      'None', 'None', '846', '1975', 'None', '2900', 'None', 'None', 'None', 'None', '2200', 'None', 'None', 'None', '2000', 'None', '2986', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1050', 'None', 'None', 'None', 'None', 'None', '1493', '2069', 'None', 'None', 'None', 'None',\n",
        "      '2821', 'None', 'None', 'None', '2000', '1657', 'None', 'None', 'None', 'None', 'None', 'None', '3619', '2472', '2525', 'None', 'None', 'None', '1500', 'None',\n",
        "      '1550', 'None', 'None', 'None', '2068', 'None', 'None', 'None', '633', 'None', '1758', 'None', '1897', 'None', '2000', 'None', 'None', 'None', '780', 'None',\n",
        "      'None', 'None', '1500', 'None', 'None', 'None', '2546', 'None', 'None', 'None', 'None', 'None', '1975', 'None', 'None', 'None', 'None', '4275', 'None', '2000',\n",
        "      '2615', 'None', 'None', 'None', 'None', '670', '1385', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '5000', 'None', '780', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', '605', 'None', 'None', '565', 'None', 'None', 'None', 'None', '1660', 'None', '1369', '1400', 'None', 'None', 'None',\n",
        "      '700', '2000', 'None', '3368', 'None', '3500', 'None', '1634', '1141', '2843', 'None', '1041', 'None', '2070', 'None', 'None', 'None', 'None', 'None', '2036',\n",
        "      'None', '5000', 'None', 'None', 'None', '2100', 'None', 'None', '3740', 'None', '1319', '846', 'None', 'None', 'None', '3000', 'None', 'None', 'None', 'None',\n",
        "      'None', '2500', 'None', '1900', '2252', 'None', 'None', 'None', 'None', 'None', '1582', '2240', '1897', '1235', 'None', '563', 'None', '1200', '3000', 'None',\n",
        "      'None', 'None', 'None', '1290', 'None', 'None', 'None', 'None', '650', 'None', '2500', '2300', '2800', 'None', 'None', 'None', 'None', 'None', '3000', 'None',\n",
        "      'None', 'None', '3000', '1453', 'None', '1800', 'None', 'None', '1100', '2400', '645', 'None', 'None', 'None', '2000', 'None', 'None', 'None', 'None', 'None',\n",
        "      '900', '1002', 'None', 'None', 'None', '1390', 'None', 'None', '1497', 'None', 'None', '1000', 'None', '1240', 'None', '789', 'None', 'None', 'None', '3000',\n",
        "      'None', 'None', 'None', 'None', '2688', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1259', 'None', 'None',\n",
        "      '3000', '885', '1100', 'None', 'None', 'None', 'None', 'None', 'None', '815', 'None', 'None', '756', 'None', '1150', 'None', 'None', '600', 'None', '1655',\n",
        "      'None', 'None', '3000', 'None', 'None', '3000', 'None', 'None', 'None', 'None', '800', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '9334',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '641', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '641', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1967',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', '5000', 'None', 'None', 'None', '2064', 'None', '1522', '800', 'None', 'None', 'None', 'None', 'None', '1259',\n",
        "      'None', 'None', 'None', 'None', 'None', '1951', 'None', 'None', '1100', 'None', 'None', '4750', '1002', 'None', 'None', 'None', 'None', 'None', 'None', '3700',\n",
        "      '4000', 'None', 'None', 'None', 'None', 'None', 'None', '1014', '885', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '765', 'None', 'None',\n",
        "      'None', 'None', 'None', '1600', 'None', 'None', 'None', 'None', 'None', '2500', 'None', 'None', 'None', 'None', '860', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', '5000', 'None', '800', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '562', '953', 'None', 'None', 'None', '1200', 'None', 'None', 'None',\n",
        "      'None', '980', 'None', 'None', 'None', 'None', 'None', '1347', 'None', 'None', 'None', 'None', '1100', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      '443', 'None', '695', 'None', 'None', 'None', 'None', 'None', 'None', '1690', '6500', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '695', 'None',\n",
        "      'None', 'None', '443', '13577', 'None', '2300', '1290', 'None', 'None', 'None', '2400', 'None', '8000', 'None', '1400', 'None', '1240', 'None', 'None', 'None',\n",
        "      '1063', 'None', 'None', 'None', 'None', 'None', 'None', '562', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', '600', '4000', 'None', 'None', 'None', 'None', 'None', '2064', '4200', '3400', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', '1330', '1478', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1200', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', '2581', '720', '1950', 'None', 'None', '1214', 'None', 'None', 'None', '4280', '3500', 'None', '4000', 'None', 'None',\n",
        "      '4750', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '2790', 'None', '1060', 'None', 'None', 'None', 'None',\n",
        "      'None', '2167', '3000', 'None', 'None', 'None', 'None', 'None', '1950', 'None', 'None', '1100', 'None', 'None', 'None', 'None', '1045', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', '700', 'None', 'None', 'None', 'None', '859', 'None', '4000', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      '1060', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '2525', 'None', 'None', 'None', 'None', 'None', 'None', '1804', 'None',\n",
        "      '2600', 'None', 'None', 'None', 'None', '3000', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1290', 'None',\n",
        "      'None', 'None', '5000', '2921', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '4541', '5000', 'None', '672', '1599', '3000', '4000',\n",
        "      'None', 'None', 'None', '1082', 'None', 'None', 'None', '800', 'None', 'None', 'None', 'None', 'None', '4000', 'None', 'None', 'None', '7166', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', '1043', 'None', '2000', 'None', 'None', 'None', '1585', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', '6000', 'None', 'None', 'None', '1682', 'None', 'None', 'None', '7000', 'None', '1214', 'None', 'None', 'None', '1600', '4000', 'None', 'None', '1060',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1100', 'None', 'None', 'None', '5400', 'None', 'None',\n",
        "      '2600', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1430', '5000', 'None', 'None', 'None', '2000', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', 'None', '4570', '854', '1024', 'None', '1599', 'None', 'None', 'None', '4500', 'None', '2500', 'None', '1800', 'None', 'None', 'None', 'None', '14863',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', '2600', 'None', 'None', '1261', 'None', '4000', 'None', '3074', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '4000', '966', '620', '1000', 'None', 'None', '2800', '3333',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', 'None', '765', 'None', 'None', 'None', '2644', 'None', 'None', 'None', '1024', 'None', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '3448', '1325', 'None', 'None', 'None', 'None', '1851', 'None', 'None', '1127',\n",
        "      'None', 'None', '1095', '827', '5000', 'None', '558', 'None', 'None', 'None', '1339', '4000', 'None', 'None', '1300', 'None', '1300', 'None', '1097', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', '827', 'None', 'None', '995', 'None', '4000', '641', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      '720', 'None', '1800', 'None', 'None', 'None', 'None', 'None', 'None', '3800', 'None', '664', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "      '943', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '966', 'None', '1049', '1049', '1075', 'None', 'None', 'None', 'None', 'None', 'None', '713',\n",
        "      '1100', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '600', 'None', 'None', 'None', 'None', '1095', 'None', '760', 'None', 'None', '1043', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '2650', 'None', '672', 'None', '2288', 'None', 'None', 'None', 'None', 'None',\n",
        "      'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '4000', 'None', '8400', '2000', 'None',\n",
        "      '2184', 'None', 'None', '2950', '1127', 'None', 'None', 'None', 'None', '1100', '1900', 'None', '1733', '1600', 'None', 'None', 'None', 'None', '713', 'None',\n",
        "      'None', 'None', '995', 'None', '1045', '760', 'None', 'None', 'None', 'None', '799', 'None', 'None', 'None', 'None', 'None', 'None', '600', 'None', 'None',\n",
        "      '700', 'None', 'None', 'None', 'None', 'None', '1200', '5500', '615', '1990', 'None', '2595', '700', '3000', '3101', '1028', 'None', 'None', '2199', 'None',\n",
        "      '2800', 'None', '2144', '984', '3330', '2038', '1846', 'None', '646', 'None', 'None', '1650', 'None', '1078', '2792', '4109', 'None', 'None', '1840', '1752',\n",
        "      '1116', '1850', 'None', 'None', '1114', 'None', '2208', 'None', 'None', '2913', 'None', '1154', '2169', 'None', 'None', 'None', '1029', '3787', '1800', 'None',\n",
        "      '3300', 'None', '1374', '2100', 'None', 'None', '4118', 'None', 'None', 'None', 'None', 'None', 'None', '3258', '1237', 'None', '2195', '3350', 'None', '1450',\n",
        "      '2265', '913', '1270', '1000', '784', '1300', '2471', '1064', 'None', '1617', '3496', '650', '1550', 'None', 'None', '1161', 'None', '1520', 'None', 'None',\n",
        "      '4268', 'None', '2285', '1107', '1630', '808', 'None', '1460', '1154', '750', '1154', '1300', '1880', '29952', 'None', '3242', '861', 'None', 'None', 'None',\n",
        "      'None', '1100', '1946', '1078', 'None', '961', '2700', '3261', 'None', 'None', 'None', 'None', '2901', '1600', '2948', 'None', 'None', '2147', '660', '1285',\n",
        "      'None', 'None', '2352', '1626', '2463', '500', 'None', 'None', '545', '1154', 'None', '1508', '1555', '3217', '1370', 'None', '1161', 'None', 'None', '1161',\n",
        "      'None', 'None', '9000', 'None', '549', 'None', 'None', '1217', 'None', '5957', '1372', '6000', '1749', 'None', 'None', '762', 'None', '545', '2666', '2253',\n",
        "      '682', '907', '2152', '1639', 'None', 'None', '1930', '1116', '1000', '1300', '3350', '966', '2351', '1848', '1070', 'None', 'None', 'None', '1260', '1229',\n",
        "      '856', '1445', 'None', '1740', 'None', 'None', '1956', '1116', 'None', 'None', 'None', '1994', '1614', '1154', 'None', 'None', '4909', 'None', '1886', '1776',\n",
        "      'None', 'None', '861', '2364', '1446', 'None', 'None', 'None', 'None', '500', '2223', '500', '1687', '762', '450', '1154', 'None', '2076', '1013', '1237',\n",
        "      '1161', '1734', '1146', '2000', '1080', '2703', '1542', '1876', '1803', 'None', '2756', 'None', '3878', 'None', 'None', '964', 'None', '2733', '2200', '500',\n",
        "      'None', '2575', 'None', '2024', '1779', '1665', '1665', 'None', '1278', 'None', '1015', 'None', 'None', '1950', '1506', '1402', 'None', '1018', '1055', '5957',\n",
        "      'None', 'None', '1838', '1886', '1714', '808', '1994', '2300', 'None', '3000', '2368', 'None', '2316', 'None', '1116', '3780', '1000', 'None', 'None', '500',\n",
        "      '1154', '2097', 'None', 'None', 'None', '2153', 'None', '2165', 'None', 'None', '689', 'None', 'None', '3900', 'None', '3100', '2296', '1154', '1500', '3516',\n",
        "      '1423', '3000', 'None', '961', 'None', 'None', '3744', '1510', '1770', '1900', '1800', 'None', '1158', '3340', '1044', '853', '1709', 'None', '1641', '1475',\n",
        "      '1116', '2374', '3345', '1094', '1154', 'None', 'None', '1380', 'None', '1288', '1260', '1549', 'None', '1273', 'None', '1925', '2500', '950', 'None', 'None',\n",
        "      '1975', '1005', '700', '920', '2733', '2162', 'None', '3395', 'None', 'None', '3300', '1799', '2845', '1466', '1660', 'None', 'None', '1736', '545', '2925',\n",
        "      'None', 'None', 'None', '2121', 'None', '1506', 'None', 'None', 'None', '1666', 'None', '8222', 'None', 'None', '1264', '1250', '1384', 'None', 'None', '2942',\n",
        "      '2200', 'None', '700', '4633', 'None', '3078', 'None', '2036', '1450', '2366', '3896', 'None', '1609', 'None', '900', '545', '1650', '2123', '2230', '2193',\n",
        "      'None', '1413', '2664', 'None', '5771', '1632', '1154', 'None', '1189', 'None', '527', '1519', '920', 'None', '1583', 'None', 'None', 'None', '2000', '2560',\n",
        "      '976', '913', 'None', 'None', '1436', 'None', '488', '1071', '1398', '545', '1501', '545', '2309', 'None', '1500', 'None', 'None', '1639', '2288', '2193',\n",
        "      'None', '6394', 'None', 'None', '3696', '545', 'None', 'None', '1300', 'None', '749', '1887', '1772', '1766', 'None', '1284', '3430', '1894', '2824', '2418',\n",
        "      '1922', 'None', '2133', '785', '1411', 'None', 'None', '1154', '2063', 'None', 'None', '1154', 'None', '2400', 'None', '1687', '1947', '1294', 'None', '1311',\n",
        "      'None', 'None', '2487', '2629', '650', '1146', 'None', 'None', '1926', 'None', '1387', 'None', 'None', 'None', '1750', '4687', '1654', '1730', '1786', 'None',\n",
        "      'None', 'None', 'None', '2708', '4220', '6000', 'None', 'None', 'None', '1200', 'None', '1500', '2440', '1402', 'None', '579', '1494', '1938', '941', '2250',\n",
        "      '2038', '1786', 'None', 'None', '1765', '1260', '1535', '1383', 'None', 'None', '2597', 'None', '629', '6912', 'None', '2643', 'None', 'None', 'None', 'None',\n",
        "      '2230', 'None', '897', '6000', 'None', 'None', '1230', '540', '1806', '1996', 'None', '500', 'None', '1562', '753', 'None', '798', 'None', '961', 'None',\n",
        "      '2400', '3018', '1325', '1149', 'None', 'None', '1154', '1154', '1000', '1550', 'None', 'None', '1505', '3800', '2577', 'None', 'None', 'None', '1700', '2100',\n",
        "      '2160', '1520', '1229', 'None', '625', '2470', 'None', '500', 'None', '10129', '2217', '2107', '1928', 'None', 'None', 'None', '2590', 'None', '1400', 'None',\n",
        "      '1959', '1294', '4000', '3892', 'None', '2040', '3600', '1220', 'None', '1400', '627', 'None', '1764', '487', '2132', 'None', '1314', '500', '500', '2947',\n",
        "      '2190', '3265', '1100', 'None', 'None', '990', 'None', '1649', 'None', '737', 'None', 'None', '1388', 'None', 'None', '1900', '1088', '1890', '917', '1166',\n",
        "      '1154', '2174', '1851', '1708', '2888', '1622', '2914', '2159', '765', '2181', 'None', '2147', '1154', 'None', 'None', '2094'\n",
        "      ]\n",
        "      to_pop = [845, 1504, 1554, 1882, 1891, 1926, 1943] ## This had to be added due to inconsistencies in the datasets when I transfered over all the data. I'm not sure why it happened but 7 entries were unable to be processed using the code in this ipynb file to open the JSON file.\n",
        "      for pop in to_pop:\n",
        "          sqfootage.pop(pop)\n",
        "      self.df.insert(len(self.df.iloc[0]), \"square_footage\", sqfootage)\n",
        "\n",
        "\n",
        "    def handle_missing_values(self):\n",
        "        \"\"\"\n",
        "        Handles missing values in the DataFrame.\n",
        "        \"\"\"\n",
        "\n",
        "        # Drop rows with missing 'listPrice'\n",
        "        self.df.dropna(subset=['listPrice'], inplace=True)\n",
        "\n",
        "        # Convert relevant columns to numeric (replace non-numeric with NaN)\n",
        "        numerical_features = ['yearBuilt', 'latitude', 'longitude', 'numBedrooms', 'numBathrooms', 'lotSize', 'parking', 'square_footage', 'garage']\n",
        "        for col in numerical_features:\n",
        "            self.df[col] = pd.to_numeric(self.df[col], errors='coerce')\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        numerical_features = ['yearBuilt', 'latitude', 'longitude', 'numBedrooms', 'numBathrooms', 'lotSize', 'parking', 'square_footage', 'garage']\n",
        "        self.df[numerical_features] = scaler.fit_transform(self.df[numerical_features])\n",
        "\n",
        "        # Impute missing year built using KNNImputer\n",
        "        imputer = KNNImputer(n_neighbors=5)\n",
        "        self.df['yearBuilt'] = imputer.fit_transform(self.df[['yearBuilt', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'latitude', 'longitude']])\n",
        "\n",
        "        # Impute missing lot size using KNNImputer\n",
        "        imputer = KNNImputer(n_neighbors=5)\n",
        "        self.df['lotSize'] = imputer.fit_transform(self.df[['lotSize', 'numBedrooms', 'numBathrooms', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'parking']])\n",
        "\n",
        "        # Impute missing square footage using KNNImputer\n",
        "        imputer = KNNImputer(n_neighbors=5)\n",
        "        self.df['square_footage'] = imputer.fit_transform(self.df[['square_footage', 'numBedrooms', 'numBathrooms', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'parking']])\n",
        "\n",
        "        # Impute missing garage using KNNImputer\n",
        "        imputer = KNNImputer(n_neighbors=5)\n",
        "        self.df['garage'] = imputer.fit_transform(self.df[['garage', 'numBedrooms', 'numBathrooms', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'parking']])\n",
        "\n",
        "        # Drop remaining rows with any NaN values in specified columns\n",
        "        columns_to_check = ['garage', 'parking', 'numBedrooms', 'numBathrooms', 'square_footage']\n",
        "        self.df.dropna(subset=columns_to_check, inplace=True)\n",
        "\n",
        "    def one_hot_encode_categorical_features(self):\n",
        "        \"\"\"\n",
        "        Performs one-hot encoding on selected categorical features.\n",
        "        \"\"\"\n",
        "        categorical_features = ['propertyType', 'Amenities_Utilities_Heating_Cooling_Cooling', 'Amenities_Utilities_Heating_Cooling_Heat_Source']\n",
        "        self.df = pd.get_dummies(self.df, columns=categorical_features, drop_first=True) * 1\n",
        "\n",
        "        # Fix column names (because of values and their one-hot encoding)\n",
        "        self.df.columns = self.df.columns.str.replace(r' +', '_', regex=True)\n",
        "\n",
        "class HousingModelTrainer:\n",
        "    \"\"\"\n",
        "    Class to train and evaluate different regression models for housing price prediction.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, test_size=0.2, random_state=42):\n",
        "        \"\"\"\n",
        "        Initializes the HousingModelTrainer with the processed DataFrame, test size, and random state.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        df : pandas.DataFrame\n",
        "            The processed DataFrame containing housing data.\n",
        "        test_size : float, optional\n",
        "            The proportion of the data to be used for testing (default is 0.2).\n",
        "        random_state : int, optional\n",
        "            The seed for random number generation (default is 42).\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.test_size = test_size\n",
        "        self.random_state = random_state\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = self.split_data()\n",
        "        self.models = self.define_models()\n",
        "        self.param_grids = self.define_param_grids()\n",
        "        self.best_models = self.train_models()\n",
        "\n",
        "    def split_data(self):\n",
        "        \"\"\"\n",
        "        Splits the data into training and testing sets.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        tuple\n",
        "            A tuple containing X_train, X_test, y_train, y_test.\n",
        "        \"\"\"\n",
        "        X = self.df.drop('listPrice', axis=1)\n",
        "        y = self.df['listPrice']\n",
        "        return train_test_split(X, y, test_size=self.test_size, random_state=self.random_state)\n",
        "\n",
        "    def define_models(self):\n",
        "        \"\"\"\n",
        "        Defines the regression models to be trained.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        dict\n",
        "            A dictionary containing the models with their names as keys.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'Linear Regression': LinearRegression(),\n",
        "            'Ridge': Ridge(),\n",
        "            'Lasso': Lasso(max_iter=5000),\n",
        "            'ElasticNet': ElasticNet(max_iter=5000),\n",
        "            'Decision Tree': DecisionTreeRegressor(),\n",
        "            'Random Forest': RandomForestRegressor(),\n",
        "            'Gradient Boosting': GradientBoostingRegressor()\n",
        "        }\n",
        "\n",
        "    def define_param_grids(self):\n",
        "        \"\"\"\n",
        "        Defines the hyperparameter grids for grid search.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        dict\n",
        "            A dictionary containing the parameter grids for each model.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'Ridge': {'alpha': np.logspace(-3, 3, 10)},\n",
        "            'Lasso': {'alpha': np.logspace(-3, 3, 10)},\n",
        "            'ElasticNet': {'alpha': np.logspace(-5, 0, 10), 'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
        "            'Decision Tree': {'max_depth': [5, 10, 20, 35, 50], 'min_samples_split': [2, 5, 10, 25, 50]},\n",
        "            'Random Forest': {'n_estimators': [100, 200, 500], 'max_depth': [5, 10, 20, 35, 50]},\n",
        "            'Gradient Boosting': {'n_estimators': [100, 200, 500], 'learning_rate': [0.01, 0.1, 1]}\n",
        "        }\n",
        "\n",
        "    def train_models(self):\n",
        "        \"\"\"\n",
        "        Trains the models using GridSearchCV for hyperparameter tuning.\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        dict\n",
        "            A dictionary containing the best trained models with their names as keys.\n",
        "        \"\"\"\n",
        "        best_models = {}\n",
        "        for name, model in self.models.items():\n",
        "            if name in self.param_grids:\n",
        "                grid_search = GridSearchCV(model, self.param_grids[name], cv=5, scoring='neg_mean_squared_error')\n",
        "                grid_search.fit(self.X_train, self.y_train)\n",
        "                best_models[name] = grid_search.best_estimator_\n",
        "                print(f'Best parameters for {name}: {grid_search.best_params_}')\n",
        "            else:\n",
        "                model.fit(self.X_train, self.y_train)\n",
        "                best_models[name] = model\n",
        "\n",
        "        ensemble = VotingRegressor(estimators=list(best_models.items()))\n",
        "        ensemble.fit(self.X_train, self.y_train)\n",
        "        best_models['ensemble'] = ensemble\n",
        "        print('\\n***************')\n",
        "\n",
        "        return best_models\n",
        "\n",
        "    def evaluate_models(self):\n",
        "        \"\"\"\n",
        "        Evaluates the trained models using various regression metrics.\n",
        "        \"\"\"\n",
        "        for name, model in self.best_models.items():\n",
        "            y_pred = model.predict(self.X_test)\n",
        "            print(f'Model: {name}')\n",
        "            if name == 'Lasso' or name == 'Ridge' or name == 'ElasticNet':\n",
        "              coefficients = model.coef_\n",
        "              feature_names = self.X_train.columns\n",
        "              for i in range(len(coefficients)):\n",
        "                  print(f'{feature_names[i]}: {coefficients[i]}')\n",
        "              # print(f'Model: {model.coef_}')\n",
        "              print(f'Features In: {model.n_features_in_}')\n",
        "              print(f'Intercept: {model.intercept_}')\n",
        "            # elif name == 'Decision Tree':\n",
        "            print(f'Params: {model.get_params()}')\n",
        "            print(f'MSE: {mean_squared_error(self.y_test, y_pred)}')\n",
        "            print(f'R-squared: {r2_score(self.y_test, y_pred)}')\n",
        "            print(f'MAE: {mean_absolute_error(self.y_test, y_pred)}')\n",
        "            print(f'RMSE: {np.sqrt(mean_squared_error(self.y_test, y_pred))}')\n",
        "            print(f'%Error: { abs(sum(self.y_test) - sum(y_pred))/sum(self.y_test) * 100 }%')\n",
        "            #print('---')\n",
        "            print('\\n***************\\n\\n')\n",
        "\n",
        "\n",
        "\n",
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/3253/ontario_housing_cleaned.json'\n",
        "\n",
        "data_processor = HousingDataProcessor(file_path)\n",
        "data_processor.clean_data()\n",
        "\n",
        "model_trainer = HousingModelTrainer(data_processor.df)\n",
        "model_trainer.evaluate_models()\n",
        "\n",
        "# Explanation of parameters passed to models:\n",
        "\n",
        "# - alpha (Ridge, Lasso, ElasticNet): Regularization parameter. Controls the strength of regularization.\n",
        "# - l1_ratio (ElasticNet): The mixing parameter between L1 and L2 penalty.\n",
        "# - max_depth (Decision Tree, Random Forest): The maximum depth of the tree.\n",
        "# - min_samples_split (Decision Tree): The minimum number of samples required to split an internal node.\n",
        "# - n_estimators (Random Forest, Gradient Boosting): The number of trees in the forest.\n",
        "# - learning_rate (Gradient Boosting): Shrinks the contribution of each tree.\n",
        "\n",
        "# Explanation of evaluation metrics:\n",
        "\n",
        "# - MSE (Mean Squared Error): Measures the average squared difference between the predicted values and the actual values.\n",
        "# - R-squared: Indicates the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
        "# - MAE (Mean Absolute Error): Measures the average absolute difference between the predicted values and the actual values.\n",
        "# - RMSE (Root Mean Squared Error): The square root of MSE, provides an interpretable metric in the same units as the target variable.\n",
        "# - %Error: Indicates the percentage error in the total prediction of the model on the test set."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV46IqnWKiLQ",
        "outputId": "8280c602-c8e7-4e84-fbed-60a1c7eb4adf"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Number of columns with missing values: 35 \n",
            "\n",
            "cityCode 13.600000000000001 % missing values\n",
            "closePrice 100.0 % missing values\n",
            "closeDate 100.0 % missing values\n",
            "listDate 38.5 % missing values\n",
            "listingCoAgent 0.1 % missing values\n",
            "listingAgent 0.1 % missing values\n",
            "lotSizeRaw 95.19999999999999 % missing values\n",
            "sqftTotalRaw 3.8 % missing values\n",
            "openHouses 95.0 % missing values\n",
            "parking 0.5 % missing values\n",
            "yearBuiltRaw 87.4 % missing values\n",
            "priceChanged 97.2 % missing values\n",
            "dateHidden 100.0 % missing values\n",
            "neighborhoodNGeoId 7.7 % missing values\n",
            "soldDate 100.0 % missing values\n",
            "propertyDateHidden 100.0 % missing values\n",
            "priceChangeAmount 97.39999999999999 % missing values\n",
            "thumbnail 1.7999999999999998 % missing values\n",
            "photoCount1 1.7999999999999998 % missing values\n",
            "garage 49.5 % missing values\n",
            "virtualTourLink 74.3 % missing values\n",
            "fsa 0.0 % missing values\n",
            "petiteImagePath 1.7999999999999998 % missing values\n",
            "propertyTypeNameUrl 5.3 % missing values\n",
            "virtualLink 71.2 % missing values\n",
            "is3DTour 74.3 % missing values\n",
            "isPriceUp 99.3 % missing values\n",
            "priceChangeRaw 97.39999999999999 % missing values\n",
            "priceChange 97.39999999999999 % missing values\n",
            "priceChangeFriendlyPrice 97.39999999999999 % missing values\n",
            "lastListPriceRaw 97.39999999999999 % missing values\n",
            "lastListPrice 97.39999999999999 % missing values\n",
            "pricePerAcre 99.1 % missing values\n",
            "pricePerAcreRaw 99.1 % missing values\n",
            "pricePerAcreIntRaw 99.1 % missing values\n",
            "\n",
            "***************\n",
            "\n",
            "\n",
            "Best parameters for Ridge: {'alpha': 0.001}\n",
            "Best parameters for Lasso: {'alpha': 2.154434690031882}\n",
            "Best parameters for ElasticNet: {'alpha': 3.5938136638046256e-05, 'l1_ratio': 0.99}\n",
            "Best parameters for Decision Tree: {'max_depth': 50, 'min_samples_split': 25}\n",
            "Best parameters for Random Forest: {'max_depth': 50, 'n_estimators': 200}\n",
            "Best parameters for Gradient Boosting: {'learning_rate': 0.1, 'n_estimators': 500}\n",
            "\n",
            "***************\n",
            "Model: Linear Regression\n",
            "Params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}\n",
            "MSE: 346789342969.66266\n",
            "R-squared: 0.5563631971628512\n",
            "MAE: 311936.4672812258\n",
            "RMSE: 588888.2262107664\n",
            "%Error: 2.3234617514405294%\n",
            "\n",
            "***************\n",
            "\n",
            "\n",
            "Model: Ridge\n",
            "latitude: 6327169.8158127265\n",
            "longitude: 32734824.47739378\n",
            "lotSize: -50120.17011717588\n",
            "numBathrooms: 5628703.418567851\n",
            "numBedrooms: -2061182.8181532812\n",
            "parking: 2335842.2253321935\n",
            "yearBuilt: 383451.5124848362\n",
            "garage: 444570.9755464489\n",
            "distance_to_lake: -2769.6833434590712\n",
            "square_footage: 9705841.459951377\n",
            "propertyType_Multi_Family: -11939.596316762714\n",
            "propertyType_Single_Family: 33974.49242415572\n",
            "propertyType_TOWNHOUSE: -105867.95649332686\n",
            "Amenities_Utilities_Heating_Cooling_Cooling_Y: 35926.66978516863\n",
            "Amenities_Utilities_Heating_Cooling_Heat_Source_Gas: -50332.356339959166\n",
            "Amenities_Utilities_Heating_Cooling_Heat_Source_Other: 85275.45541030378\n",
            "Features In: 16\n",
            "Intercept: -6656464.819696927\n",
            "Params: {'alpha': 0.001, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}\n",
            "MSE: 346984443311.4264\n",
            "R-squared: 0.5561136113736476\n",
            "MAE: 311565.4826744961\n",
            "RMSE: 589053.8543388256\n",
            "%Error: 2.323008436739926%\n",
            "\n",
            "***************\n",
            "\n",
            "\n",
            "Model: Lasso\n",
            "latitude: 6434867.38223086\n",
            "longitude: 33133378.494489096\n",
            "lotSize: -46969.272042965764\n",
            "numBathrooms: 5620268.050009224\n",
            "numBedrooms: -2055770.6520474046\n",
            "parking: 2339108.4308249974\n",
            "yearBuilt: 386271.96535367914\n",
            "garage: 441638.79709027533\n",
            "distance_to_lake: -2800.9952129668827\n",
            "square_footage: 9704738.002448466\n",
            "propertyType_Multi_Family: -8636.671642324349\n",
            "propertyType_Single_Family: 36105.33076386364\n",
            "propertyType_TOWNHOUSE: -105013.92996849633\n",
            "Amenities_Utilities_Heating_Cooling_Cooling_Y: 36415.110592886165\n",
            "Amenities_Utilities_Heating_Cooling_Heat_Source_Gas: -51880.64988047033\n",
            "Amenities_Utilities_Heating_Cooling_Heat_Source_Other: 85392.12720152408\n",
            "Features In: 16\n",
            "Intercept: -6769204.675437839\n",
            "Params: {'alpha': 2.154434690031882, 'copy_X': True, 'fit_intercept': True, 'max_iter': 5000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}\n",
            "MSE: 346826082348.16003\n",
            "R-squared: 0.5563161976204916\n",
            "MAE: 311821.97152770864\n",
            "RMSE: 588919.4192316637\n",
            "%Error: 2.3243160303824943%\n",
            "\n",
            "***************\n",
            "\n",
            "\n",
            "Model: ElasticNet\n",
            "latitude: 6353940.345048219\n",
            "longitude: 32784961.815314654\n",
            "lotSize: -50404.459295306035\n",
            "numBathrooms: 5628100.980085836\n",
            "numBedrooms: -2061642.3466103256\n",
            "parking: 2336419.6573565365\n",
            "yearBuilt: 383980.49769513705\n",
            "garage: 444384.1769408647\n",
            "distance_to_lake: -2772.2005856329174\n",
            "square_footage: 9705872.436268296\n",
            "propertyType_Multi_Family: -11610.753139531964\n",
            "propertyType_Single_Family: 34036.678565361566\n",
            "propertyType_TOWNHOUSE: -105692.9351625922\n",
            "Amenities_Utilities_Heating_Cooling_Cooling_Y: 35971.74865128829\n",
            "Amenities_Utilities_Heating_Cooling_Heat_Source_Gas: -50505.09934392117\n",
            "Amenities_Utilities_Heating_Cooling_Heat_Source_Other: 85308.37440371604\n",
            "Features In: 16\n",
            "Intercept: -6683611.166243242\n",
            "Params: {'alpha': 3.5938136638046256e-05, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.99, 'max_iter': 5000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}\n",
            "MSE: 346963912379.35406\n",
            "R-squared: 0.5561398759554419\n",
            "MAE: 311602.325240785\n",
            "RMSE: 589036.4270394099\n",
            "%Error: 2.323058111959006%\n",
            "\n",
            "***************\n",
            "\n",
            "\n",
            "Model: Decision Tree\n",
            "Params: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 50, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 25, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n",
            "MSE: 264973204378.96463\n",
            "R-squared: 0.6610280344212256\n",
            "MAE: 250638.07662098034\n",
            "RMSE: 514755.48018351843\n",
            "%Error: 0.05962915736725655%\n",
            "\n",
            "***************\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 50, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
            "MSE: 169026224189.9106\n",
            "R-squared: 0.7837700171143756\n",
            "MAE: 193647.81918797697\n",
            "RMSE: 411127.9900346249\n",
            "%Error: 1.811574357542968%\n",
            "\n",
            "***************\n",
            "\n",
            "\n",
            "Model: Gradient Boosting\n",
            "Params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 500, 'n_iter_no_change': None, 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
            "MSE: 138950781704.64658\n",
            "R-squared: 0.8222445937372285\n",
            "MAE: 191114.72417654967\n",
            "RMSE: 372761.02492702554\n",
            "%Error: 1.9320354647728177%\n",
            "\n",
            "***************\n",
            "\n",
            "\n",
            "Model: ensemble\n",
            "Params: {'estimators': [('Linear Regression', LinearRegression()), ('Ridge', Ridge(alpha=0.001)), ('Lasso', Lasso(alpha=2.154434690031882, max_iter=5000)), ('ElasticNet', ElasticNet(alpha=3.5938136638046256e-05, l1_ratio=0.99, max_iter=5000)), ('Decision Tree', DecisionTreeRegressor(max_depth=50, min_samples_split=25)), ('Random Forest', RandomForestRegressor(max_depth=50, n_estimators=200)), ('Gradient Boosting', GradientBoostingRegressor(n_estimators=500))], 'n_jobs': None, 'verbose': False, 'weights': None, 'Linear Regression': LinearRegression(), 'Ridge': Ridge(alpha=0.001), 'Lasso': Lasso(alpha=2.154434690031882, max_iter=5000), 'ElasticNet': ElasticNet(alpha=3.5938136638046256e-05, l1_ratio=0.99, max_iter=5000), 'Decision Tree': DecisionTreeRegressor(max_depth=50, min_samples_split=25), 'Random Forest': RandomForestRegressor(max_depth=50, n_estimators=200), 'Gradient Boosting': GradientBoostingRegressor(n_estimators=500), 'Linear Regression__copy_X': True, 'Linear Regression__fit_intercept': True, 'Linear Regression__n_jobs': None, 'Linear Regression__positive': False, 'Ridge__alpha': 0.001, 'Ridge__copy_X': True, 'Ridge__fit_intercept': True, 'Ridge__max_iter': None, 'Ridge__positive': False, 'Ridge__random_state': None, 'Ridge__solver': 'auto', 'Ridge__tol': 0.0001, 'Lasso__alpha': 2.154434690031882, 'Lasso__copy_X': True, 'Lasso__fit_intercept': True, 'Lasso__max_iter': 5000, 'Lasso__positive': False, 'Lasso__precompute': False, 'Lasso__random_state': None, 'Lasso__selection': 'cyclic', 'Lasso__tol': 0.0001, 'Lasso__warm_start': False, 'ElasticNet__alpha': 3.5938136638046256e-05, 'ElasticNet__copy_X': True, 'ElasticNet__fit_intercept': True, 'ElasticNet__l1_ratio': 0.99, 'ElasticNet__max_iter': 5000, 'ElasticNet__positive': False, 'ElasticNet__precompute': False, 'ElasticNet__random_state': None, 'ElasticNet__selection': 'cyclic', 'ElasticNet__tol': 0.0001, 'ElasticNet__warm_start': False, 'Decision Tree__ccp_alpha': 0.0, 'Decision Tree__criterion': 'squared_error', 'Decision Tree__max_depth': 50, 'Decision Tree__max_features': None, 'Decision Tree__max_leaf_nodes': None, 'Decision Tree__min_impurity_decrease': 0.0, 'Decision Tree__min_samples_leaf': 1, 'Decision Tree__min_samples_split': 25, 'Decision Tree__min_weight_fraction_leaf': 0.0, 'Decision Tree__random_state': None, 'Decision Tree__splitter': 'best', 'Random Forest__bootstrap': True, 'Random Forest__ccp_alpha': 0.0, 'Random Forest__criterion': 'squared_error', 'Random Forest__max_depth': 50, 'Random Forest__max_features': 1.0, 'Random Forest__max_leaf_nodes': None, 'Random Forest__max_samples': None, 'Random Forest__min_impurity_decrease': 0.0, 'Random Forest__min_samples_leaf': 1, 'Random Forest__min_samples_split': 2, 'Random Forest__min_weight_fraction_leaf': 0.0, 'Random Forest__n_estimators': 200, 'Random Forest__n_jobs': None, 'Random Forest__oob_score': False, 'Random Forest__random_state': None, 'Random Forest__verbose': 0, 'Random Forest__warm_start': False, 'Gradient Boosting__alpha': 0.9, 'Gradient Boosting__ccp_alpha': 0.0, 'Gradient Boosting__criterion': 'friedman_mse', 'Gradient Boosting__init': None, 'Gradient Boosting__learning_rate': 0.1, 'Gradient Boosting__loss': 'squared_error', 'Gradient Boosting__max_depth': 3, 'Gradient Boosting__max_features': None, 'Gradient Boosting__max_leaf_nodes': None, 'Gradient Boosting__min_impurity_decrease': 0.0, 'Gradient Boosting__min_samples_leaf': 1, 'Gradient Boosting__min_samples_split': 2, 'Gradient Boosting__min_weight_fraction_leaf': 0.0, 'Gradient Boosting__n_estimators': 500, 'Gradient Boosting__n_iter_no_change': None, 'Gradient Boosting__random_state': None, 'Gradient Boosting__subsample': 1.0, 'Gradient Boosting__tol': 0.0001, 'Gradient Boosting__validation_fraction': 0.1, 'Gradient Boosting__verbose': 0, 'Gradient Boosting__warm_start': False}\n",
            "MSE: 175736011118.85898\n",
            "R-squared: 0.7751863957280127\n",
            "MAE: 233564.85858313143\n",
            "RMSE: 419208.7917957578\n",
            "%Error: 1.8321548947359039%\n",
            "\n",
            "***************\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}