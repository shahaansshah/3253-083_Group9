{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install python-geohash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMj27sqCeKLG",
        "outputId": "440d844d-51ca-467a-824f-f404fb30532a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-geohash\n",
            "  Downloading python-geohash-0.8.5.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python-geohash\n",
            "  Building wheel for python-geohash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-geohash: filename=python_geohash-0.8.5-cp310-cp310-linux_x86_64.whl size=41537 sha256=ed658e8691826ca6f7cd61c4a6b72a252d9b5c96958c430aa7dc5a91db771777\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/e8/74/3f800ffdbb57c27a3fee3a695c7009769356448837c1f4f899\n",
            "Successfully built python-geohash\n",
            "Installing collected packages: python-geohash\n",
            "Successfully installed python-geohash-0.8.5\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from geohash import encode\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "# Assuming you have the JSON data in a file named 'data.json' in your Google Drive\n",
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the path to your JSON file\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/3253/ontario_housing_cleaned.json'\n",
        "\n",
        "# Load the JSON data from the file line by line\n",
        "records = []\n",
        "with open(file_path, 'r') as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            data = json.loads(line) # Load each line as a separate JSON object\n",
        "            record = data.get('data') # Use .get() to handle potential missing 'data' key\n",
        "            if record is not None: # Check if 'data' exists and is not None\n",
        "                features = {}\n",
        "                for feature_group in record.get('features', []): # Handle cases where 'features' might be missing\n",
        "                    for feature_category in feature_group.get('value', []):\n",
        "                        for feature in feature_category.get('value', []):\n",
        "                            features[f\"{feature_group['name']}_{feature_category['name']}_{feature['name']}\"] = feature['value']\n",
        "\n",
        "                record.update(features)  # Add the extracted features to the record\n",
        "                record.pop('features', None)  # Remove the original nested features structure if it exists\n",
        "                records.append(record)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Skipping invalid JSON line: {line}\") # Log any lines that fail to parse\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "#df.to_csv('/content/drive/MyDrive/Colab Notebooks/3253/ontario_housing_cleaned.csv', index=False)\n",
        "\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head())"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D0yBVG0_bKG",
        "outputId": "6d6bc3c0-474c-40d6-9b4f-bcb1242eafcb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                         address subPremise  \\\n",
            "0  2480 Prince Michael Dr S #210       #210   \n",
            "1                 1176 Grange Rd              \n",
            "2                 3511 Post Road              \n",
            "3            95 Dundas St W #513       #513   \n",
            "4          3137 William Rose Way              \n",
            "\n",
            "                                         fullAddress       division      city  \\\n",
            "0  2480 Prince Michael Dr S #210 Oakville, ON L6H...  Halton Region  Oakville   \n",
            "1                1176 Grange Rd Oakville, ON L6H 1P6  Halton Region  Oakville   \n",
            "2                3511 Post Road Oakville, ON L6H 7W5                 Oakville   \n",
            "3           95 Dundas St W #513 Oakville, ON L6M 5N4  Halton Region  Oakville   \n",
            "4         3137 William Rose Way Oakville, ON L6H 0T1  Halton Region  Oakville   \n",
            "\n",
            "   cityCode closePrice closeDate daysOnMovoto  daysOnMovotoRaw  ... is3DTour  \\\n",
            "0    2506.0       None      None      14 days               14  ...      NaN   \n",
            "1    2506.0       None      None  Just Listed                0  ...      NaN   \n",
            "2       NaN       None      None       6 days                6  ...      NaN   \n",
            "3    2506.0       None      None      34 days               34  ...      NaN   \n",
            "4    2506.0       None      None      76 days               76  ...     True   \n",
            "\n",
            "  isPriceUp priceChangeRaw priceChange priceChangeFriendlyPrice  \\\n",
            "0       NaN            NaN         NaN                      NaN   \n",
            "1       NaN            NaN         NaN                      NaN   \n",
            "2       NaN            NaN         NaN                      NaN   \n",
            "3       NaN            NaN         NaN                      NaN   \n",
            "4       NaN            NaN         NaN                      NaN   \n",
            "\n",
            "   lastListPriceRaw lastListPrice pricePerAcre pricePerAcreRaw  \\\n",
            "0               NaN           NaN          NaN             NaN   \n",
            "1               NaN           NaN          NaN             NaN   \n",
            "2               NaN           NaN          NaN             NaN   \n",
            "3               NaN           NaN          NaN             NaN   \n",
            "4               NaN           NaN          NaN             NaN   \n",
            "\n",
            "  pricePerAcreIntRaw  \n",
            "0                NaN  \n",
            "1                NaN  \n",
            "2                NaN  \n",
            "3                NaN  \n",
            "4                NaN  \n",
            "\n",
            "[5 rows x 200 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the specified columns\n",
        "# These features are either irrelevant for predicting price, redundant, or contain mostly null values.\n",
        "columns_to_drop = ['tnImgPath', 'imagesURL', 'photos', 'id', 'listingCoAgent', 'listingAgent',\n",
        "                   'listingAgentLicense', 'listingOfficePhone',\n",
        "                   'mlsDbNumber', 'mlsSysid', 'mls', 'mlsNumber', 'openHouses',\n",
        "                   'officeColistName', 'officeListName', 'officeListPhone', 'photoCount', 'price', 'priceSeo', 'propertyTypeValue', 'propertyTypeDisplayName'\n",
        "                   'state', 'status', 'pageUrlWithoutDomain', 'houseRealStatus', 'listingOfficeDescription', 'hoafee', 'hoafeeRaw', 'dppInactiveOnActive',\n",
        "                   'dppInactive', 'priceChanged', 'priceChangedDate', 'updatedTime', 'hiddenByComplianceRule', 'dateHidden', 'propertyId', 'visibility',\n",
        "                   'permitAvm', 'modificationTimestamp', 'createdAt', 'propertyDateHidden', 'imageDownloaderStatus', 'onMarketDateTime', 'priceChangeAmount', 'thumbnail',\n",
        "                   'photoCount1', 'virtualTourLink', 'fsa', 'dppurl', 'listingByMovoto', 'labelDisplayName', 'listingPriceFormat', 'comparableHomes',\n",
        "                   'listDateLLFormat', 'listDateLLFormat', 'listDateFormat', 'listDateUTC', 'pricePerSqft', 'pricePerSqftRaw', 'pricePerSqftIntRaw', 'isFavorite',\n",
        "                   'petiteImagePath', 'propertyTypeNameUrl', 'closePrice', 'closeDate', 'daysOnMovoto', 'cityCode', 'listDate',\n",
        "                   'state', 'soldDate', 'isHotHome', 'isSold', 'isPriceReduced', 'label', 'labelclass', 'Amenities  Utilities_Other_Pets Allowed (YN)',\n",
        "                   'Amenities  Utilities_Utility_Utilities', 'Exterior_Building_# Total Stories', 'Exterior_Building_Building Amenities',\n",
        "                   'Exterior_Building_Building Amenities', 'Exterior_Other_Exterior Features', 'Exterior_Other_Fencing', 'Exterior_Building_Foundation',\n",
        "                   'Exterior_Parking_# Garage Spaces', 'Exterior_Parking_Drive', 'Exterior_Parking_Garage Features', 'Exterior_Parking_Has Basement (YN)',\n",
        "                   'Exterior_Parking_Has Garage (YN)', 'Exterior_Parking_Parking Desc', 'Exterior_Parking_Parking Spot #',\n",
        "                   'Interior_Bathrooms_# Full Baths', 'Interior_Bathrooms_# Half Baths', 'Interior_Bathrooms_# Three-Quarter', 'Interior_Bathrooms_# Total Bathrooms',\n",
        "                   'Interior_Bedrooms_Family Room Available', 'Interior_Flooring_Flooring', 'Interior_Interior_Appliances', 'Interior_Interior_Has Fireplace (YN)',\n",
        "                   'Interior_Interior_Laundry Information', 'Interior_Other_Interior Features', 'Location_Community_Community', 'Location_Community_Community Features',\n",
        "                   'Location_Community_County', 'Location_Location features_Area', 'Location_Location features_Subdivision', 'Location_Location features_View',\n",
        "                   'Location_Location features_Water Body Name', 'Location_Location features_Water Body Type', 'Location_Location features_Water Source',\n",
        "                   'Location_Location features_Zoning Description', 'Location_Other_Directions', 'Location_Schools_Elementary School', 'Location_Schools_High School',\n",
        "                   'Location_Schools_Middle School', 'Location_Schools_School District', 'Lot Land Details_Lot Information_Exposure',\n",
        "                   'Lot Land Details_Lot Information_FarmAgriculture', 'Lot Land Details_Lot Information_Lot Desc', 'Lot Land Details_Lot Information_Lot Size Units',\n",
        "                   'Lot Land Details_Lot Information_Water Features', 'Lot Land Details_Lot Information_Water Frontage', 'Overview_Lot_Approx Lot Size (Range)',\n",
        "                   'Overview_Other_Approx Age', 'Overview_Other_Is Gated Community (YN)', 'Overview_Other_Is Horse Property (YN)', 'Overview_Other_New Construction (YN)',\n",
        "                   'Overview_Other_Year Built', 'Overview_Other_HOA', 'Overview_Property_Approx Square Feet (Range)', 'Overview_Property_MLS #',\n",
        "                   'Overview_Property_Status', 'Overview_Property_Storage Unit (Locker)', 'Overview_Property_Virtual Tour', 'Overview_Taxes_Tax Year', 'Overview_Taxes_Taxes',\n",
        "                   'Rooms_Rooms Information_Movotorooms', 'SOA_HOUSEKEEPING_ATTRS_LISTING_SOURCE_URL_Listing Source URL',\n",
        "                   'SOA_HOUSEKEEPING_ATTRS_LISTING_TYPE_Listing Type Identifier', 'virtualLink', 'is3DTour', 'isPriceUp', 'priceChange', 'priceChangeFriendlyPrice',\n",
        "                   'lastListPriceRaw', 'lastListPrice', 'pricePerAcre', 'pricePerAcreRaw', 'pricePerAcreIntRaw', 'subPremise', 'fullAddress', 'division', 'daysOnMovotoRaw',\n",
        "                   'description', 'lotSizeRaw', 'sqftTotalRaw', 'neighborhoodN', 'numBathroomsRaw', 'numBedroomsRaw', 'priceRaw', 'propertyTypeName','propertyTypeDisplayName',\n",
        "                   'yearBuiltRaw', 'totalMonthlyFee', 'neighborhoodNGeoId', 'isVOWListing', 'addressRaw', 'address2', 'lotSizeUnit', 'sqftTotalUnit',\n",
        "                   'Amenities  Utilities_Utility_Sewer Septic', 'Amenities  Utilities_Heating  Cooling_Heat Type', 'Amenities  Utilities_Other_Has Pool (YN)',\n",
        "                   'Amenities  Utilities_Utility_Utility_Sewer Septic', 'Exterior_Building_Construction Materials', 'Exterior_Building_Roof',\n",
        "                   'Exterior_Other_Other Structures', 'Exterior_Parking_# Parking Spaces', 'Interior_Bathrooms_# Three-Quarter Baths',\n",
        "                   'Interior_Bedrooms_# of Above Grade Bedrooms', 'Interior_Bedrooms_# of Below Grade Bedrooms', 'Interior_Bedrooms_# of Rooms',\n",
        "                   'Interior_More rooms_# of Kitchens', 'Lot Land Details_Lot Information_Lot Dimensions', 'Overview_Lot_Lot Size (Acres)', 'Overview_Other_Maintenance Fee',\n",
        "                   'Overview_Property_Basement Information', 'Overview_Property_Building Size ', 'Overview_Property_Property Sub Type',\n",
        "                   'city', 'neighborhoodName', 'priceChangeRaw', 'address', 'zipCode', 'sqftTotal']\n",
        "# Use errors='ignore' to avoid errors if a column doesn't exist, drop in-place\n",
        "df.drop(columns=columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/3253/ontario_housing_cleaned2.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wXTkKiXTAzru"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Distance to lake calculations and adding them into the dataframe\n",
        "def distance(origin, destination):\n",
        "    \"\"\"\n",
        "    Calculate the Haversine distance.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    origin : tuple of float\n",
        "        (lat, long)\n",
        "    destination : tuple of float\n",
        "        (lat, long)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    distance_in_km : float\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> origin = (48.1372, 11.5756)  # Munich\n",
        "    >>> destination = (52.5186, 13.4083)  # Berlin\n",
        "    >>> round(distance(origin, destination), 1)\n",
        "    504.2\n",
        "    \"\"\"\n",
        "    lat1, lon1 = origin\n",
        "    lat2, lon2 = destination\n",
        "    radius = 6371  # km\n",
        "\n",
        "    dlat = math.radians(lat2 - lat1)\n",
        "    dlon = math.radians(lon2 - lon1)\n",
        "    a = (math.sin(dlat / 2) * math.sin(dlat / 2) +\n",
        "         math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) *\n",
        "         math.sin(dlon / 2) * math.sin(dlon / 2))\n",
        "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
        "    d = radius * c\n",
        "\n",
        "    return d\n",
        "shorepoints = [(43.337573, -79.769493), (43.325047, -79.792023), (43.346755, -79.758282), (43.352226, -79.751185),\n",
        "              (43.362459, -79.737418), (43.366887, -79.729100), (43.385790, -79.712277), (43.399670, -79.700950),\n",
        "              (43.419369, -79.683863), (43.451628, -79.654371), (43.467697, -79.640033), (43.486686, -79.617320),\n",
        "              (43.517525, -79.601415), (43.538370, -79.594686), (43.562755, -79.564711), (43.576052, -79.543607),\n",
        "              (43.594663, -79.503232), (43.625224, -79.478151), (43.630317, -79.433801), (43.632973, -79.407191),\n",
        "              (43.272289, -79.919314), (43.276725, -79.860298), (43.271462, -79.833200), (43.251221, -79.757855),\n",
        "          ]\n",
        "distances = []\n",
        "for id, row in df.iterrows():\n",
        "    mindist =  distance((row[\"latitude\"], row[\"longitude\"]), shorepoints[0])\n",
        "    for point in shorepoints:\n",
        "        dist = distance((row[\"latitude\"], row[\"longitude\"]), point)\n",
        "        if dist < mindist:\n",
        "            mindist = dist\n",
        "    distances.append(mindist)\n",
        "df.insert(len(df.iloc[0]), \"distance_to_lake\", distances)\n"
      ],
      "metadata": {
        "id": "u3Kgonwytwwi"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the DataFrame\n",
        "print(df.head(30).to_string())"
      ],
      "metadata": {
        "id": "z3DrxEZ3fOwQ",
        "outputId": "f1f2d237-bd6e-4ce8-fd6e-53a8acc32729",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     latitude  listPrice  longitude lotSize numBathrooms numBedrooms  parking   propertyType yearBuilt  garage Amenities  Utilities_Heating  Cooling_Cooling Amenities  Utilities_Heating  Cooling_Heat Source  distance_to_lake\n",
            "0   43.497160     995000 -79.707940                    2           2      2.0  Single Family       ...     NaN                      Central air conditioning                                       Natural gas          6.383626\n",
            "1   43.479693    1190000 -79.682036                    2           3      3.0  Single Family       ...     NaN                      Central air conditioning                                                            3.642386\n",
            "2   43.494279    1450000 -79.742757                    5           5      2.0      TOWNHOUSE       ...     1.0                                   Central Air                                               Gas          8.565083\n",
            "3   43.476904     579900 -79.732563                    1           1      1.0          Condo      2022     1.0                                   Central Air                                                            6.908122\n",
            "4   43.495964    2799900 -79.719458                    6           5      4.0  Single Family      2018     2.0                                   Central Air                                                            7.137521\n",
            "5   43.430986    1585000 -79.763201                    3           4      7.0  Single Family      2003     2.0                                   Central Air                                                            6.116135\n",
            "6   43.472162     579900 -79.682990                    1           3      1.0  Single Family       ...     NaN                                                                                        Electric          3.247854\n",
            "7   43.426402    1149777 -79.745596                    3           3      4.0      TOWNHOUSE      1991     1.0                                   Central Air                                                            4.673380\n",
            "8   43.384353    2050000 -79.729888                    5           6      4.0  Single Family       ...     NaN                      Central air conditioning                                       Natural gas          1.432110\n",
            "9   43.434140     599000 -79.774660                    1           1      0.0          Condo       ...     2.0                                   Central Air                                         Grnd Srce          7.080599\n",
            "10  43.461706    1485000 -79.698420                    3           4      5.0  Single Family      1964     1.0                                   Central Air                                                            3.727871\n",
            "11  43.460013    3099000 -79.659552                    3           3      8.0  Single Family      1956     2.0                                   Central Air                                                            1.021861\n",
            "12  43.435510     769000 -79.773360                    2           3      1.0  Single Family       ...     NaN                      Central air conditioning                                       Natural gas          7.077139\n",
            "13  43.475497    1980000 -79.745598                    5           5      4.0  Single Family       ...     NaN                      Central air conditioning                                       Natural gas          7.826398\n",
            "14  43.479600     675000 -79.725790                    2           2      1.0  Single Family       ...     NaN                      Central air conditioning                                       Natural gas          6.549466\n",
            "15  43.429299    1689000 -79.692283                    3           4      7.0  Single Family       ...     1.0                                   Central Air                                                            1.296753\n",
            "16  43.453050    4598000 -79.659093   7,841            4           3      6.0  Single Family      1997     2.0                                   Central Air                                                            0.412662\n",
            "17  43.493137    1875000 -79.717004                    4           4      4.0  Single Family       ...     NaN                      Central air conditioning                                       Natural gas          6.824249\n",
            "18  43.477005    2299900 -79.698573                    4           5      6.0  Single Family       ...     NaN                      Central air conditioning                                       Natural gas          4.548461\n",
            "19  43.473216     915000 -79.739419                    3           2      2.0      TOWNHOUSE       ...     1.0                                   Central Air                                                            7.271703\n",
            "20  43.432975     499000 -79.728113                    1           2      1.0  Single Family       ...     NaN                        Window air conditioner                                          Electric          3.880547\n",
            "21  43.383405    2367000 -79.727627                    4           4      4.0  Single Family       ...     2.0                                   Central Air                                                            1.268495\n",
            "22  43.431242    3770000 -79.701812                    6           5      6.0  Single Family       ...     2.0                                   Central Air                                                            1.960633\n",
            "23  43.449008    1089000 -79.736619                    2           3      1.0          Condo       ...     1.0                                   Central Air                                               Gas          5.385889\n",
            "24  43.452165    1499000 -79.684194                    2           2      2.0  Single Family      2001     NaN                      Central air conditioning                                                            2.408118\n",
            "25  43.447055    1899900 -79.752189                    4           6      4.0  Single Family       ...     NaN                      Central air conditioning                                       Natural gas          6.317920\n",
            "26  43.467176    1699999 -79.729418                    4           7      4.0  Single Family       ...     NaN                      Central air conditioning                                       Natural gas          6.299102\n",
            "27  43.479123     679000 -79.726034                    2           2      1.0      TOWNHOUSE      2013     1.0                                   Central Air                                                            6.541867\n",
            "28   0.000000     999000   0.000000                    3           4      1.0      TOWNHOUSE       ...     1.0                                   Central Air                                               Gas       9157.360296\n",
            "29  43.447311    1649000 -79.749356                    4           4      4.0  Single Family       ...     NaN        Central air conditioning,Air exchanger                                       Natural gas          6.133535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## THIS CODE IS ONLY PRESENT TO SHOW HOW DATA WAS COLLECTED AND DOES NOT HAVE THE REQUIRED API KEY TO RUN\n",
        "## Completing the dataset by adding missing entries of square footage using the description which includes square footage (usually) and using the AzureAI chatbot to analyze text and return the square footage or None.\n",
        "\n",
        "# Connection to openai chatbot\n",
        "deployment_name = \"REDACTED\"\n",
        "client = AzureOpenAI(\n",
        "    api_key= \"REDACTED\", ## I am not allowed to share this API key for legal reasons but it was used to message the Azure AI chatbot\n",
        "    api_version=\"2024-02-01\",\n",
        "    azure_endpoint = \"REDACTED\"\n",
        "    )\n",
        "\n",
        "def message_chatbot(message, description):\n",
        "\n",
        "    # Uses the connecetion made to make a request to the Azure openai chatbot\n",
        "    response = client.chat.completions.create(\n",
        "        model=deployment_name,\n",
        "        temperature=0.7,\n",
        "        max_tokens=400,\n",
        "\n",
        "        # Both messages to be submitted\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": message},\n",
        "            {\"role\": \"user\", \"content\": description}\n",
        "        ]\n",
        "    )\n",
        "    generated_text = response.choices[0].message.content\n",
        "\n",
        "    return (generated_text)\n",
        "\n",
        "message = \"The following will be a description of a house, Please find the total square footage of the house and return it as a single number without any commas or measurements. Do not return any other text other than the number itself, without any math equations or explanations, just a number. If there is no square footage found return 'None'\"\n",
        "sqfootage = []\n",
        "for id, row in df_cleaned.iterrows():\n",
        "    if row[\"sqftTotalRaw\"] == 0 or row[\"sqftTotalRaw\"] == None:\n",
        "        sqfootage.append(message_chatbot(message, row[\"description\"]))\n",
        "    else:\n",
        "        sqfootage.append(row[\"sqftTotalRaw\"])\n"
      ],
      "metadata": {
        "id": "iKZYVV3tcvhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Because the above code does not work without the API (and I am not allowed to put it here), this is what it wouldve generated, sorry for the hardcoding :( to be fair this isn't part of the assignment and was extra work\n",
        "## HARDCODING PRESENT DUE TO NOT HAVING THE API KEY\n",
        "sqfootage = [\n",
        "'1200',\n",
        "'None', 'None', '600', '3993', '2816', 'None', '1350', '3180', '1075', '1824', '2980', 'None', '3262', '1000', '1191', '4487', 'None', 'None', '1108', 'None',\n",
        "'2900', '5186', 'None', '1479', '4000', '3100', '950', 'None', '2500', '5246', 'None', 'None', '3214', '1400', 'None', '2000', '3537', 'None', '1800', '3284',\n",
        "'1762', '4303', '4100', '1936', '1017', '2617', '9900', '1000', '79954', '613', '1950', 'None', '2500', 'None', '1800', '1088', '1911', '2159', '1700', '4367',\n",
        "'5293', '1200', '1918', '986', '717', '2000', '1146', '6000', 'None', 'None', 'None', 'None', '3860', '6984', 'None', '3800', '715', 'None', '1990', '7476',\n",
        "'None', '610', 'None', 'None', '711', '1351', '1617', 'None', 'None', 'None', 'None', '2000', 'None', 'None', 'None', 'None', '1161', 'None', '5000', '2595',\n",
        "'None', '2702', 'None', 'None', 'None', '2018', '660', 'None', '6568', 'None', 'None', 'None', '1700', 'None', '3300', '3108', '2720', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', '1075', '2805', '4600', '3614', '2500', 'None', '1710', '1285', '4655', 'None', '2944', '4038', 'None', 'None', '3285', 'None',\n",
        "'3800', '2150', 'None', '1900', 'None', 'None', '2000', 'None', '1535', '3124', 'None', '845', 'None', '3234', 'None', '1400', 'None', 'None', 'None', '995',\n",
        "'3100', 'None', '3873', 'None', '3886', '3400', '1783', 'None', 'None', '1900', 'None', '1557', '1783', '2918', '1300', 'None', '946', '592', 'None', 'None',\n",
        "'None', '715', 'None', '3680', '3610', 'None', 'None', '2857', '1850', '3262', 'None', 'None', '2440', '2077', 'None', '4000', '6127', '479', 'None', '2734',\n",
        "'2791', 'None', 'None', '1462', 'None', 'None', 'None', '840', 'None', 'None', '6772', 'None', 'None', '4401', '3550', 'None', '756', 'None', '4423', '2250',\n",
        "'None', 'None', 'None', '3718', 'None', '9907', 'None', 'None', 'None', '1250', 'None', 'None', 'None', 'None', 'None', '3081', '2953', 'None', '962', '1535',\n",
        "'None', 'None', '1700', '6400', 'None', '1250', '7494', 'None', '500', 'None', '2159', 'None', 'None', 'None', 'None', '528', '2150', '2406', 'None', 'None',\n",
        "'None', '3143', 'None', '2856', '1900', '2789', 'None', '2767', '3000', '4364', 'None', '3921', '4000', '4680', 'None', '6416', '3430', '8750', '1000', '7500',\n",
        "'922', '1790', '2981', '1351', 'None', 'None', 'None', 'None', '3500', 'None', '4200', '3500', '2326', 'None', '3000', 'None', '1288', 'None', '1800', '1774',\n",
        "'None', '2000', '2150', '1170', '1408', '1', 'None', '5000', 'None', '1050', 'None', '2700', '2720', '1000', '3200', 'None', 'None', '2820', 'None', 'None',\n",
        "'None', '3200', '630', '3550', '1548', 'None', '1084', '8000', '1455', 'None', '6568', 'None', '5470', '2500', 'None', '3368', '820', 'None', 'None', '2041',\n",
        "'735', '1762', '4303', '854', 'None', '3400', 'None', '855', 'None', 'None', 'None', 'None', 'None', 'None', '2946', '1079', '4400', '1408', 'None', '6424',\n",
        "'None', 'None', 'None', '1990', 'None', 'None', '2210', '2593', '735', 'None', 'None', '4600', '730', '5922', '2000', 'None', '5883', 'None', '3000', '7400',\n",
        "'None', '1943', '997', '1783', '1780', '2247', 'None', '3716', '2243', '6470', '854', '1413', 'None', 'None', 'None', '6220', 'None', '1411', '1428', '1258',\n",
        "'1780', 'None', '1954', 'None', '700', '1400', '1200', '655', '2200', 'None', 'None', 'None', '2744', '3700', '1880', 'None', '6829', '1050', '1615', 'None',\n",
        "'None', 'None', 'None', '774', '1577', 'None', 'None', 'None', 'None', '700', 'None', '5000', '714', '2300', '6100', 'None', 'None', '1264', '1119', 'None',\n",
        "'5745', '4279', 'None', '3558', 'None', '4728', 'None', '1321', '4364', 'None', 'None', 'None', 'None', '2691', '1830', '4000', 'None', '972', '980', '3019',\n",
        "'None', 'None', 'None', '7715', '586', '4482', '900', 'None', '3800', '4000', '3600', 'None', '4867', '1113', '943', '620', '1250', 'None', 'None', '2971',\n",
        "'2816', '1200', '1630', 'None', 'None', 'None', '2900', 'None', '625', 'None', 'None', '3173', 'None', 'None', '3815', 'None', '2056', '1000', 'None', '3815',\n",
        "'None', '3316', '5000', '4000', '972', 'None', 'None', 'None', '1948', '4200', 'None', 'None', 'None', '2065', 'None', 'None', '3653', '1188', '2321', 'None',\n",
        "'1201', 'None', '5700', 'None', '4054', '2728', '2807', '2704', 'None', '1866', 'None', '1700', '1501', 'None', '3325', '3800', '2459', '933', '2026', '629',\n",
        "'None', 'None', '2790', '4200', '3180', '650', '2479', '613', '3700', 'None', '1830', 'None', '3999', 'None', 'None', 'None', 'None', 'None', '3605', 'None',\n",
        "'None', '4750', '1700', '1450', '3000', '916', 'None', '4597', 'None', 'None', 'None', 'None', 'None', 'None', '2000', 'None', 'None', 'None', '13400', '1700',\n",
        "'None', '469', 'None', '9413', 'None', '3741', '830', '1290', 'None', 'None', 'None', '2677', 'None', 'None', 'None', 'None', 'None', '13400', 'None', 'None',\n",
        "'5400', '2500', 'None', 'None', 'None', 'None', 'None', '2064', '3447', 'None', '830', 'None', '4000', 'None', '839', 'None', 'None', '3880', '1586', 'None',\n",
        "'1650', 'None', 'None', 'None', 'None', '1800', 'None', 'None', 'None', '1100', '1300', 'None', 'None', 'None', 'None', 'None', '2768', 'None', 'None', 'None',\n",
        "'1500', '1600', 'None', 'None', 'None', '827', 'None', 'None', 'None', 'None', 'None', 'None', '1480', 'None', 'None', 'None', 'None', '1186', '7700', '1400',\n",
        "'None', 'None', '640', '988', 'None', 'None', 'None', '576', 'None', 'None', 'None', 'None', '1000', 'None', '1655', 'None', 'None', 'None', 'None', 'None',\n",
        "'4000', 'None', 'None', '600', '3000', '9334', 'None', '1000', '1300', 'None', 'None', '2676', '1300', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', '1800', 'None', '784', '590', 'None', '3111', '608', 'None', 'None', 'None', 'None', 'None', '1405', '841', '1087', 'None', 'None', 'None', '1136',\n",
        "'None', '1100', '1870', 'None', 'None', '2777', 'None', 'None', 'None', 'None', 'None', 'None', '400', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', '3000', 'None', 'None', 'None', '756', '821', '1347', 'None', 'None', '1150', 'None', 'None', '5500', 'None', 'None', '910', '1300', 'None', 'None',\n",
        "'1655', 'None', 'None', '1350', '1575', '566', 'None', 'None', '800', 'None', '1100', '948', '1100', '1203', '1186', 'None', 'None', 'None', '1032', 'None',\n",
        "'None', '9334', '4410', '1179', '965', 'None', 'None', 'None', 'None', 'None', '965', 'None', 'None', 'None', 'None', '2651', 'None', 'None', 'None', 'None',\n",
        "'1275', 'None', 'None', 'None', 'None', 'None', 'None', '560', '691', 'None', '3500', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', '4300', 'None', 'None', '600', 'None', '1500', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '3000', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', 'None', '2924', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '2500', '723', 'None', '4126', '630', 'None', 'None', 'None', 'None', '800',\n",
        "'None', 'None', 'None', '821', 'None', 'None', '562', 'None', 'None', 'None', '1685', '846', '3000', 'None', '1933', 'None', 'None', 'None', 'None', '5000',\n",
        "'4400', 'None', 'None', 'None', 'None', '1100', '4760', '2986', '836', 'None', 'None', 'None', 'None', 'None', 'None', '560', '3638', '1136', 'None', 'None',\n",
        "'None', 'None', '4000', 'None', '910', 'None', '982', '3282', 'None', 'None', '700', 'None', 'None', 'None', 'None', 'None', '3063', '3631', '2300', 'None',\n",
        "'None', 'None', '723', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1050', '576', 'None', 'None', '940', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', '1370', 'None', '5500', '2636', 'None', '1138', 'None', '800', 'None', 'None', '1138', 'None', 'None', 'None', '716', 'None',\n",
        "'None', 'None', 'None', '3705', '1360', '3296', 'None', 'None', 'None', 'None', 'None', 'None', '540', 'None', '1700', 'None', 'None', 'None', 'None', '562',\n",
        "'953', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1500', 'None', 'None', '703', '4000', 'None', '2360', 'None', 'None',\n",
        "'2020', '1347', 'None', 'None', 'None', '1084', 'None', '1100', 'None', 'None', 'None', 'None', '580', '1174', 'None', 'None', '982', 'None', 'None', '728',\n",
        "'None', '810', '795', 'None', 'None', '810', 'None', 'None', '1690', 'None', 'None', '1625', 'None', '6500', '2500', 'None', 'None', '784', 'None', '3073',\n",
        "'None', 'None', 'None', 'None', '756', '1032', '2000', 'None', 'None', 'None', 'None', 'None', '2300', 'None', '700', 'None', '2215', '1179', 'None', 'None',\n",
        "'None', '630', '2300', '1290', '1000', '3000', '799', 'None', 'None', 'None', '2064', 'None', 'None', '4400', 'None', 'None', '1343', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', '1150', '562', '566', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1200', '875', 'None', 'None', '948', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', 'None', '1041', '1655', 'None', 'None', 'None', 'None', 'None', '1300', 'None', 'None', 'None', 'None', 'None',\n",
        "'2070', '562', 'None', 'None', 'None', '5000', 'None', 'None', '515', 'None', '2050', '2100', 'None', 'None', 'None', 'None', '1626', 'None', 'None', 'None',\n",
        "'None', 'None', '846', 'None', 'None', 'None', '5000', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'3500', '4075', 'None', 'None', 'None', '1025', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '800', 'None', 'None', 'None', '563', '2000', '1483',\n",
        "'None', 'None', 'None', 'None', '1405', 'None', 'None', 'None', '1100', 'None', '2197', 'None', 'None', '2677', 'None', '1338', 'None', '1897', 'None', 'None',\n",
        "'1405', '2200', 'None', '830', 'None', '1483', 'None', 'None', 'None', '1157', 'None', 'None', '1369', 'None', 'None', '2622', '1000', '1010', 'None', '2194',\n",
        "'None', 'None', '4000', 'None', 'None', '1549', 'None', '3000', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', '2100', 'None', 'None', 'None', 'None', 'None', '993', 'None', '785', '2309', 'None', '1132', '1447', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', '1416', 'None', 'None', 'None', '2600', 'None', 'None', 'None', '984', 'None', 'None', 'None', 'None', 'None', '1383', 'None', 'None',\n",
        "'None', 'None', '1141', 'None', '0000', '3297', '1358', 'None', '3000', '3092', 'None', 'None', 'None', 'None', 'None', 'None', '1860', '1158', '1772', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', '1500', '1483', 'None', 'None', 'None', 'None', 'None', 'None', '1900', '1313', 'None', 'None', 'None', 'None', 'None',\n",
        "'1300', 'None', '1441', '3092', '1000', '2500', 'None', 'None', '2350', '2651', 'None', 'None', 'None', 'None', '1589', 'None', '1736', 'None', 'None', 'None',\n",
        "'2812', '1324', 'None', 'None', '4409', '1072', 'None', 'None', 'None', 'None', '3400', '2700', '2158', 'None', '1185', '2252', 'None', 'None', 'None', '1615',\n",
        "'None', '879', '2615', 'None', '1978', 'None', '1000', '998', 'None', 'None', 'None', '1897', 'None', '1608', 'None', '1500', 'None', '700', 'None', 'None',\n",
        "'None', 'None', '846', '1975', 'None', '2900', 'None', 'None', 'None', 'None', '2200', 'None', 'None', 'None', '2000', 'None', '2986', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1050', 'None', 'None', 'None', 'None', 'None', '1493', '2069', 'None', 'None', 'None', 'None',\n",
        "'2821', 'None', 'None', 'None', '2000', '1657', 'None', 'None', 'None', 'None', 'None', 'None', '3619', '2472', '2525', 'None', 'None', 'None', '1500', 'None',\n",
        "'1550', 'None', 'None', 'None', '2068', 'None', 'None', 'None', '633', 'None', '1758', 'None', '1897', 'None', '2000', 'None', 'None', 'None', '780', 'None',\n",
        "'None', 'None', '1500', 'None', 'None', 'None', '2546', 'None', 'None', 'None', 'None', 'None', '1975', 'None', 'None', 'None', 'None', '4275', 'None', '2000',\n",
        "'2615', 'None', 'None', 'None', 'None', '670', '1385', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '5000', 'None', '780', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', '605', 'None', 'None', '565', 'None', 'None', 'None', 'None', '1660', 'None', '1369', '1400', 'None', 'None', 'None',\n",
        "'700', '2000', 'None', '3368', 'None', '3500', 'None', '1634', '1141', '2843', 'None', '1041', 'None', '2070', 'None', 'None', 'None', 'None', 'None', '2036',\n",
        "'None', '5000', 'None', 'None', 'None', '2100', 'None', 'None', '3740', 'None', '1319', '846', 'None', 'None', 'None', '3000', 'None', 'None', 'None', 'None',\n",
        "'None', '2500', 'None', '1900', '2252', 'None', 'None', 'None', 'None', 'None', '1582', '2240', '1897', '1235', 'None', '563', 'None', '1200', '3000', 'None',\n",
        "'None', 'None', 'None', '1290', 'None', 'None', 'None', 'None', '650', 'None', '2500', '2300', '2800', 'None', 'None', 'None', 'None', 'None', '3000', 'None',\n",
        "'None', 'None', '3000', '1453', 'None', '1800', 'None', 'None', '1100', '2400', '645', 'None', 'None', 'None', '2000', 'None', 'None', 'None', 'None', 'None',\n",
        "'900', '1002', 'None', 'None', 'None', '1390', 'None', 'None', '1497', 'None', 'None', '1000', 'None', '1240', 'None', '789', 'None', 'None', 'None', '3000',\n",
        "'None', 'None', 'None', 'None', '2688', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1259', 'None', 'None',\n",
        "'3000', '885', '1100', 'None', 'None', 'None', 'None', 'None', 'None', '815', 'None', 'None', '756', 'None', '1150', 'None', 'None', '600', 'None', '1655',\n",
        "'None', 'None', '3000', 'None', 'None', '3000', 'None', 'None', 'None', 'None', '800', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '9334',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '641', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '641', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1967',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', '5000', 'None', 'None', 'None', '2064', 'None', '1522', '800', 'None', 'None', 'None', 'None', 'None', '1259',\n",
        "'None', 'None', 'None', 'None', 'None', '1951', 'None', 'None', '1100', 'None', 'None', '4750', '1002', 'None', 'None', 'None', 'None', 'None', 'None', '3700',\n",
        "'4000', 'None', 'None', 'None', 'None', 'None', 'None', '1014', '885', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '765', 'None', 'None',\n",
        "'None', 'None', 'None', '1600', 'None', 'None', 'None', 'None', 'None', '2500', 'None', 'None', 'None', 'None', '860', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', '5000', 'None', '800', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '562', '953', 'None', 'None', 'None', '1200', 'None', 'None', 'None',\n",
        "'None', '980', 'None', 'None', 'None', 'None', 'None', '1347', 'None', 'None', 'None', 'None', '1100', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'443', 'None', '695', 'None', 'None', 'None', 'None', 'None', 'None', '1690', '6500', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '695', 'None',\n",
        "'None', 'None', '443', '13577', 'None', '2300', '1290', 'None', 'None', 'None', '2400', 'None', '8000', 'None', '1400', 'None', '1240', 'None', 'None', 'None',\n",
        "'1063', 'None', 'None', 'None', 'None', 'None', 'None', '562', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', '600', '4000', 'None', 'None', 'None', 'None', 'None', '2064', '4200', '3400', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', '1330', '1478', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1200', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', '2581', '720', '1950', 'None', 'None', '1214', 'None', 'None', 'None', '4280', '3500', 'None', '4000', 'None', 'None',\n",
        "'4750', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '2790', 'None', '1060', 'None', 'None', 'None', 'None',\n",
        "'None', '2167', '3000', 'None', 'None', 'None', 'None', 'None', '1950', 'None', 'None', '1100', 'None', 'None', 'None', 'None', '1045', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', '700', 'None', 'None', 'None', 'None', '859', 'None', '4000', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'1060', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '2525', 'None', 'None', 'None', 'None', 'None', 'None', '1804', 'None',\n",
        "'2600', 'None', 'None', 'None', 'None', '3000', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1290', 'None',\n",
        "'None', 'None', '5000', '2921', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '4541', '5000', 'None', '672', '1599', '3000', '4000',\n",
        "'None', 'None', 'None', '1082', 'None', 'None', 'None', '800', 'None', 'None', 'None', 'None', 'None', '4000', 'None', 'None', 'None', '7166', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', '1043', 'None', '2000', 'None', 'None', 'None', '1585', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', '6000', 'None', 'None', 'None', '1682', 'None', 'None', 'None', '7000', 'None', '1214', 'None', 'None', 'None', '1600', '4000', 'None', 'None', '1060',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1100', 'None', 'None', 'None', '5400', 'None', 'None',\n",
        "'2600', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '1430', '5000', 'None', 'None', 'None', '2000', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', 'None', '4570', '854', '1024', 'None', '1599', 'None', 'None', 'None', '4500', 'None', '2500', 'None', '1800', 'None', 'None', 'None', 'None', '14863',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', '2600', 'None', 'None', '1261', 'None', '4000', 'None', '3074', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '4000', '966', '620', '1000', 'None', 'None', '2800', '3333',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', 'None', '765', 'None', 'None', 'None', '2644', 'None', 'None', 'None', '1024', 'None', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '3448', '1325', 'None', 'None', 'None', 'None', '1851', 'None', 'None', '1127',\n",
        "'None', 'None', '1095', '827', '5000', 'None', '558', 'None', 'None', 'None', '1339', '4000', 'None', 'None', '1300', 'None', '1300', 'None', '1097', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', '827', 'None', 'None', '995', 'None', '4000', '641', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'720', 'None', '1800', 'None', 'None', 'None', 'None', 'None', 'None', '3800', 'None', '664', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None',\n",
        "'943', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '966', 'None', '1049', '1049', '1075', 'None', 'None', 'None', 'None', 'None', 'None', '713',\n",
        "'1100', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '600', 'None', 'None', 'None', 'None', '1095', 'None', '760', 'None', 'None', '1043', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '2650', 'None', '672', 'None', '2288', 'None', 'None', 'None', 'None', 'None',\n",
        "'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', '4000', 'None', '8400', '2000', 'None',\n",
        "'2184', 'None', 'None', '2950', '1127', 'None', 'None', 'None', 'None', '1100', '1900', 'None', '1733', '1600', 'None', 'None', 'None', 'None', '713', 'None',\n",
        "'None', 'None', '995', 'None', '1045', '760', 'None', 'None', 'None', 'None', '799', 'None', 'None', 'None', 'None', 'None', 'None', '600', 'None', 'None',\n",
        "'700', 'None', 'None', 'None', 'None', 'None', '1200', '5500', '615', '1990', 'None', '2595', '700', '3000', '3101', '1028', 'None', 'None', '2199', 'None',\n",
        "'2800', 'None', '2144', '984', '3330', '2038', '1846', 'None', '646', 'None', 'None', '1650', 'None', '1078', '2792', '4109', 'None', 'None', '1840', '1752',\n",
        "'1116', '1850', 'None', 'None', '1114', 'None', '2208', 'None', 'None', '2913', 'None', '1154', '2169', 'None', 'None', 'None', '1029', '3787', '1800', 'None',\n",
        "'3300', 'None', '1374', '2100', 'None', 'None', '4118', 'None', 'None', 'None', 'None', 'None', 'None', '3258', '1237', 'None', '2195', '3350', 'None', '1450',\n",
        "'2265', '913', '1270', '1000', '784', '1300', '2471', '1064', 'None', '1617', '3496', '650', '1550', 'None', 'None', '1161', 'None', '1520', 'None', 'None',\n",
        "'4268', 'None', '2285', '1107', '1630', '808', 'None', '1460', '1154', '750', '1154', '1300', '1880', '29952', 'None', '3242', '861', 'None', 'None', 'None',\n",
        "'None', '1100', '1946', '1078', 'None', '961', '2700', '3261', 'None', 'None', 'None', 'None', '2901', '1600', '2948', 'None', 'None', '2147', '660', '1285',\n",
        "'None', 'None', '2352', '1626', '2463', '500', 'None', 'None', '545', '1154', 'None', '1508', '1555', '3217', '1370', 'None', '1161', 'None', 'None', '1161',\n",
        "'None', 'None', '9000', 'None', '549', 'None', 'None', '1217', 'None', '5957', '1372', '6000', '1749', 'None', 'None', '762', 'None', '545', '2666', '2253',\n",
        "'682', '907', '2152', '1639', 'None', 'None', '1930', '1116', '1000', '1300', '3350', '966', '2351', '1848', '1070', 'None', 'None', 'None', '1260', '1229',\n",
        "'856', '1445', 'None', '1740', 'None', 'None', '1956', '1116', 'None', 'None', 'None', '1994', '1614', '1154', 'None', 'None', '4909', 'None', '1886', '1776',\n",
        "'None', 'None', '861', '2364', '1446', 'None', 'None', 'None', 'None', '500', '2223', '500', '1687', '762', '450', '1154', 'None', '2076', '1013', '1237',\n",
        "'1161', '1734', '1146', '2000', '1080', '2703', '1542', '1876', '1803', 'None', '2756', 'None', '3878', 'None', 'None', '964', 'None', '2733', '2200', '500',\n",
        "'None', '2575', 'None', '2024', '1779', '1665', '1665', 'None', '1278', 'None', '1015', 'None', 'None', '1950', '1506', '1402', 'None', '1018', '1055', '5957',\n",
        "'None', 'None', '1838', '1886', '1714', '808', '1994', '2300', 'None', '3000', '2368', 'None', '2316', 'None', '1116', '3780', '1000', 'None', 'None', '500',\n",
        "'1154', '2097', 'None', 'None', 'None', '2153', 'None', '2165', 'None', 'None', '689', 'None', 'None', '3900', 'None', '3100', '2296', '1154', '1500', '3516',\n",
        "'1423', '3000', 'None', '961', 'None', 'None', '3744', '1510', '1770', '1900', '1800', 'None', '1158', '3340', '1044', '853', '1709', 'None', '1641', '1475',\n",
        "'1116', '2374', '3345', '1094', '1154', 'None', 'None', '1380', 'None', '1288', '1260', '1549', 'None', '1273', 'None', '1925', '2500', '950', 'None', 'None',\n",
        "'1975', '1005', '700', '920', '2733', '2162', 'None', '3395', 'None', 'None', '3300', '1799', '2845', '1466', '1660', 'None', 'None', '1736', '545', '2925',\n",
        "'None', 'None', 'None', '2121', 'None', '1506', 'None', 'None', 'None', '1666', 'None', '8222', 'None', 'None', '1264', '1250', '1384', 'None', 'None', '2942',\n",
        "'2200', 'None', '700', '4633', 'None', '3078', 'None', '2036', '1450', '2366', '3896', 'None', '1609', 'None', '900', '545', '1650', '2123', '2230', '2193',\n",
        "'None', '1413', '2664', 'None', '5771', '1632', '1154', 'None', '1189', 'None', '527', '1519', '920', 'None', '1583', 'None', 'None', 'None', '2000', '2560',\n",
        "'976', '913', 'None', 'None', '1436', 'None', '488', '1071', '1398', '545', '1501', '545', '2309', 'None', '1500', 'None', 'None', '1639', '2288', '2193',\n",
        "'None', '6394', 'None', 'None', '3696', '545', 'None', 'None', '1300', 'None', '749', '1887', '1772', '1766', 'None', '1284', '3430', '1894', '2824', '2418',\n",
        "'1922', 'None', '2133', '785', '1411', 'None', 'None', '1154', '2063', 'None', 'None', '1154', 'None', '2400', 'None', '1687', '1947', '1294', 'None', '1311',\n",
        "'None', 'None', '2487', '2629', '650', '1146', 'None', 'None', '1926', 'None', '1387', 'None', 'None', 'None', '1750', '4687', '1654', '1730', '1786', 'None',\n",
        "'None', 'None', 'None', '2708', '4220', '6000', 'None', 'None', 'None', '1200', 'None', '1500', '2440', '1402', 'None', '579', '1494', '1938', '941', '2250',\n",
        "'2038', '1786', 'None', 'None', '1765', '1260', '1535', '1383', 'None', 'None', '2597', 'None', '629', '6912', 'None', '2643', 'None', 'None', 'None', 'None',\n",
        "'2230', 'None', '897', '6000', 'None', 'None', '1230', '540', '1806', '1996', 'None', '500', 'None', '1562', '753', 'None', '798', 'None', '961', 'None',\n",
        "'2400', '3018', '1325', '1149', 'None', 'None', '1154', '1154', '1000', '1550', 'None', 'None', '1505', '3800', '2577', 'None', 'None', 'None', '1700', '2100',\n",
        "'2160', '1520', '1229', 'None', '625', '2470', 'None', '500', 'None', '10129', '2217', '2107', '1928', 'None', 'None', 'None', '2590', 'None', '1400', 'None',\n",
        "'1959', '1294', '4000', '3892', 'None', '2040', '3600', '1220', 'None', '1400', '627', 'None', '1764', '487', '2132', 'None', '1314', '500', '500', '2947',\n",
        "'2190', '3265', '1100', 'None', 'None', '990', 'None', '1649', 'None', '737', 'None', 'None', '1388', 'None', 'None', '1900', '1088', '1890', '917', '1166',\n",
        "'1154', '2174', '1851', '1708', '2888', '1622', '2914', '2159', '765', '2181', 'None', '2147', '1154', 'None', 'None', '2094'\n",
        "]\n",
        "to_pop = [845, 1504, 1554, 1882, 1891, 1926, 1943] ## This had to be added due to inconsistencies in the datasets when I transfered over all the data. I'm not sure why it happened but 7 entries were unable to be processed using the code in this ipynb file to open the JSON file.\n",
        "for pop in to_pop:\n",
        "    sqfootage.pop(pop)\n",
        "df.insert(len(df.iloc[0]), \"square_footage\", sqfootage)"
      ],
      "metadata": {
        "id": "PqeJQmQcc27S"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.copy()\n",
        "\n",
        "#print(df2.head(30).to_string())\n",
        "\n",
        "\n",
        "## Create Geohash Feature\n",
        "#df2['geohash'] = df2.apply(lambda row: encode(row['latitude'], row['longitude'], precision=6), axis=1)\n",
        "#df2.drop(columns=['latitude', 'longitude'], inplace=True, errors='ignore')\n",
        "\n",
        "## Drop Rows with Missing 'listPrice', and show how many were dropped\n",
        "print(f\"Number of rows with missing 'listPrice': {df2['listPrice'].isna().sum()}\")\n",
        "df2.dropna(subset=['listPrice'], inplace=True)\n",
        "\n",
        "# Drop outliers that will add noise to the model, not going to predict for outliers\n",
        "# Drop propertyType in 'FARM', 'Land', 'Other', 'Multi Family'\n",
        "df2 = df2[~df2['propertyType'].isin(['FARM', 'Land', 'Other', 'Multi_Family'])]\n",
        "# Drop garage greater than 4\n",
        "###df2 = df2[df2['garage'] <= 4]\n",
        "\n",
        "# Fix column names\n",
        "df2.columns = df2.columns.str.replace(r' +', '_', regex=True)\n",
        "\n",
        "# Categorical variables levels cleanup\n",
        "df2['Amenities_Utilities_Heating_Cooling_Cooling'] = df2['Amenities_Utilities_Heating_Cooling_Cooling'].str.replace(r'Ductless.*|.*Central .*', 'Y', regex=True)\n",
        "df2['Amenities_Utilities_Heating_Cooling_Cooling'] = df2['Amenities_Utilities_Heating_Cooling_Cooling'].str.replace(r'^(?!.*Y).*', 'N', regex=True)\n",
        "df2['Amenities_Utilities_Heating_Cooling_Heat_Source'] = df2['Amenities_Utilities_Heating_Cooling_Heat_Source'].str.replace(r'Electric.*', 'Electric', regex=True)\n",
        "df2['Amenities_Utilities_Heating_Cooling_Heat_Source'] = df2['Amenities_Utilities_Heating_Cooling_Heat_Source'].str.replace(r'Natural gas.*', 'Gas', regex=True)\n",
        "df2['Amenities_Utilities_Heating_Cooling_Heat_Source'] = df2['Amenities_Utilities_Heating_Cooling_Heat_Source'].str.replace(r'^(?!Electric|Gas).*', 'Other', regex=True)\n",
        "\n",
        "\n",
        "## 1.6. One-Hot Encode Categorical Features\n",
        "# One-hot encode categorical features: 'city', 'neighborhoodName', 'propertyType', 'parking', 'garage', 'Amenities  Utilities_Heating  Cooling_Cooling', 'Amenities  Utilities_Heating  Cooling_Heat Type'\n",
        "categorical_features = ['propertyType', 'Amenities_Utilities_Heating_Cooling_Cooling', 'Amenities_Utilities_Heating_Cooling_Heat_Source']\n",
        "df2 = pd.get_dummies(df2, columns=categorical_features, drop_first=True)*1\n",
        "\n",
        "# Fix column names (because of values and their one-hot encoding)\n",
        "df2.columns = df2.columns.str.replace(r' +', '_', regex=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Impute Missing Values\n",
        "\n",
        "# Impute missing year built with the median year built for the property type\n",
        "#df2['yearBuilt'] = df2.groupby('propertyType')['yearBuilt'].transform(lambda x: x.fillna(x.median()))\n",
        "# replace all non-numeric values in column df2[['yearBuilt']] with Nan\n",
        "df2['yearBuilt'] = pd.to_numeric(df2['yearBuilt'], errors='coerce')\n",
        "df2['numBedrooms'] = pd.to_numeric(df2['numBedrooms'], errors='coerce')\n",
        "df2['numBathrooms'] = pd.to_numeric(df2['numBathrooms'], errors='coerce')\n",
        "df2['lotSize'] = pd.to_numeric(df2['lotSize'], errors='coerce')\n",
        "df2['square_footage'] = pd.to_numeric(df2['square_footage'], errors='coerce')\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = ['yearBuilt', 'latitude', 'longitude', 'numBedrooms', 'numBathrooms', 'lotSize', 'parking', 'square_footage', 'garage']\n",
        "df2[numerical_features] = scaler.fit_transform(df2[numerical_features])\n",
        "\n",
        "# Impute yearBuilt using KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "# Scale yearBuilt for KNNImputer\n",
        "df2['yearBuilt'] = imputer.fit_transform(df2[['yearBuilt', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'latitude', 'longitude']])\n",
        "\n",
        "# Impute missing lot size based on median lot size for similar properties (same property type, city, and number of bedrooms)\n",
        "#df2['lotSize'] = df2.groupby(['propertyType', 'numBedrooms', 'numBathrooms'])['lotSize'].transform(lambda x: x.fillna(x.median()))\n",
        "# Impute lotSize based on numBedrooms and numBathrooms using KNNImputer\n",
        "\n",
        "#imputer = KNNImputer(n_neighbors=5)\n",
        "df2['lotSize'] = imputer.fit_transform(df2[['lotSize', 'numBedrooms', 'numBathrooms', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'parking']])\n",
        "\n",
        "# Similar imputation strategy as 'lotSize'\n",
        "#df2['square_footage'] = df2.groupby(['propertyType', 'numBedrooms', 'numBathrooms'])['square_footage'].transform(lambda x: x.fillna(x.median()))\n",
        "\n",
        "#imputer = KNNImputer(n_neighbors=5)\n",
        "df2['square_footage'] = imputer.fit_transform(df2[['square_footage', 'numBedrooms', 'numBathrooms', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'parking']])\n",
        "\n",
        "#imputer = KNNImputer(n_neighbors=5)\n",
        "df2['garage'] = imputer.fit_transform(df2[['garage', 'numBedrooms', 'numBathrooms', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'parking']])\n",
        "\n",
        "#imputer = KNNImputer(n_neighbors=5)\n",
        "df2['distance_to_lake'] = imputer.fit_transform(df2[['square_footage', 'numBedrooms', 'numBathrooms', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'parking']])\n",
        "\n",
        "# drop all rows that have NaN in any column\n",
        "columns_to_check = ['garage', 'parking', 'numBedrooms', 'numBathrooms', 'square_footage']\n",
        "df2.dropna(subset=columns_to_check, inplace=True)\n",
        "\n",
        "#print(df2[[]].isna().sum())\n",
        "print(df2.head(30).to_string())\n",
        "#print(df2.to_string())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G98OC-Y4PfzV",
        "outputId": "78afe6eb-c936-4cd5-da14-f05926f3ba87"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with missing 'listPrice': 0\n",
            "    latitude  listPrice  longitude   lotSize  numBathrooms  numBedrooms   parking  yearBuilt    garage  distance_to_lake  square_footage  propertyType_Multi_Family  propertyType_Single_Family  propertyType_TOWNHOUSE  Amenities_Utilities_Heating_Cooling_Cooling_Y  Amenities_Utilities_Heating_Cooling_Heat_Source_Gas  Amenities_Utilities_Heating_Cooling_Heat_Source_Other\n",
            "0   0.984358     995000   0.010590  0.007382      0.028571     0.022222  0.045455   0.928000  0.026316          0.040064        0.040064                          0                           1                       0                                              1                                                    1                                                      0\n",
            "1   0.983963    1190000   0.010911  0.007382      0.028571     0.044444  0.068182   0.869333  0.026316          0.046995        0.046995                          0                           1                       0                                              1                                                    0                                                      1\n",
            "2   0.984293    1450000   0.010157  0.424847      0.114286     0.088889  0.045455   0.968889  0.026316          0.076175        0.076175                          0                           0                       1                                              1                                                    1                                                      0\n",
            "3   0.983900     579900   0.010284  0.362211      0.000000     0.000000  0.022727   0.986667  0.026316          0.020032        0.020032                          0                           0                       0                                              1                                                    0                                                      1\n",
            "4   0.984331    2799900   0.010447  0.007382      0.142857     0.088889  0.090909   0.968889  0.052632          0.133313        0.133313                          0                           1                       0                                              1                                                    0                                                      1\n",
            "5   0.982861    1585000   0.009904  0.007437      0.057143     0.066667  0.159091   0.902222  0.052632          0.094017        0.094017                          0                           1                       0                                              1                                                    0                                                      1\n",
            "6   0.983793     579900   0.010899  0.007382      0.000000     0.044444  0.022727   0.821333  0.005263          0.025260        0.025260                          0                           1                       0                                              0                                                    0                                                      0\n",
            "7   0.982757    1149777   0.010122  0.424847      0.057143     0.044444  0.090909   0.848889  0.026316          0.045072        0.045072                          0                           0                       1                                              1                                                    0                                                      1\n",
            "8   0.981806    2050000   0.010317  0.007382      0.114286     0.111111  0.090909   0.873778  0.052632          0.106170        0.106170                          0                           1                       0                                              1                                                    1                                                      0\n",
            "9   0.982932     599000   0.009761  0.362167      0.000000     0.000000  0.000000   0.880889  0.052632          0.035891        0.035891                          0                           0                       0                                              1                                                    0                                                      1\n",
            "10  0.983556    1485000   0.010708  0.007382      0.057143     0.066667  0.113636   0.728889  0.026316          0.060897        0.060897                          0                           1                       0                                              1                                                    0                                                      1\n",
            "11  0.983518    3099000   0.011190  0.000169      0.057143     0.044444  0.181818   0.693333  0.052632          0.099493        0.099493                          0                           1                       0                                              1                                                    0                                                      1\n",
            "12  0.982963     769000   0.009778  0.007382      0.028571     0.044444  0.022727   0.909333  0.026316          0.034615        0.034615                          0                           1                       0                                              1                                                    1                                                      0\n",
            "13  0.983868    1980000   0.010122  0.007382      0.114286     0.088889  0.090909   0.941333  0.052632          0.108908        0.108908                          0                           1                       0                                              1                                                    1                                                      0\n",
            "14  0.983961     675000   0.010368  0.007382      0.028571     0.022222  0.022727   0.951111  0.015789          0.033387        0.033387                          0                           1                       0                                              1                                                    1                                                      0\n",
            "15  0.982823    1689000   0.010784  0.007437      0.057143     0.066667  0.159091   0.857778  0.026316          0.039764        0.039764                          0                           1                       0                                              1                                                    0                                                      1\n",
            "16  0.983360    4598000   0.011196  0.007382      0.085714     0.044444  0.136364   0.875556  0.052632          0.149806        0.149806                          0                           1                       0                                              1                                                    0                                                      1\n",
            "17  0.984267    1875000   0.010477  0.007382      0.085714     0.066667  0.090909   0.947556  0.073684          0.105869        0.105869                          0                           1                       0                                              1                                                    1                                                      0\n",
            "18  0.983902    2299900   0.010706  0.007382      0.085714     0.088889  0.136364   0.877333  0.052632          0.108547        0.108547                          0                           1                       0                                              1                                                    1                                                      0\n",
            "19  0.983817     915000   0.010199  0.424847      0.057143     0.022222  0.045455   0.958222  0.026316          0.036993        0.036993                          0                           0                       1                                              1                                                    0                                                      1\n",
            "20  0.982906     499000   0.010339  0.007382      0.000000     0.022222  0.022727   0.851556  0.010526          0.020780        0.020780                          0                           1                       0                                              0                                                    0                                                      0\n",
            "21  0.981784    2367000   0.010345  0.007382      0.085714     0.066667  0.090909   0.873778  0.052632          0.096822        0.096822                          0                           1                       0                                              1                                                    0                                                      1\n",
            "22  0.982867    3770000   0.010666  0.007333      0.142857     0.088889  0.136364   0.864000  0.052632          0.173144        0.173144                          0                           1                       0                                              1                                                    0                                                      1\n",
            "23  0.983269    1089000   0.010234  0.362167      0.028571     0.044444  0.022727   0.968889  0.026316          0.031931        0.031931                          0                           0                       0                                              1                                                    1                                                      0\n",
            "24  0.983340    1499000   0.010884  0.007382      0.028571     0.022222  0.045455   0.893333  0.026316          0.049379        0.049379                          0                           1                       0                                              1                                                    0                                                      1\n",
            "25  0.983225    1899900   0.010040  0.007382      0.085714     0.111111  0.090909   0.888000  0.052632          0.133547        0.133547                          0                           1                       0                                              1                                                    1                                                      0\n",
            "26  0.983680    1699999   0.010323  0.007382      0.085714     0.133333  0.090909   0.908444  0.052632          0.103499        0.103499                          0                           1                       0                                              1                                                    1                                                      0\n",
            "27  0.983950     679000   0.010365  0.424847      0.028571     0.022222  0.022727   0.946667  0.026316          0.031717        0.031717                          0                           0                       1                                              1                                                    0                                                      1\n",
            "28  0.000000     999000   1.000000  0.424847      0.057143     0.066667  0.022727   0.887111  0.026316          0.057178        0.057178                          0                           0                       1                                              1                                                    1                                                      0\n",
            "29  0.983230    1649000   0.010076  0.007382      0.085714     0.066667  0.090909   0.888000  0.073684          0.083467        0.083467                          0                           1                       0                                              1                                                    1                                                      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ## 1.7. Handle Outliers\n",
        "# # Identify outliers in 'listPrice' based on IQR and remove them\n",
        "# Q1 = df2['listPrice'].quantile(0.25)\n",
        "# Q3 = df2['listPrice'].quantile(0.75)\n",
        "# IQR = Q3 - Q1\n",
        "# upper_bound = Q3 + 1.5 * IQR\n",
        "# lower_bound = Q1 - 1.5 * IQR\n",
        "# df2 = df2[(df2['listPrice'] >= lower_bound) & (df2['listPrice'] <= upper_bound)]\n",
        "\n",
        "# 2. Feature Engineering\n",
        "\n",
        "## 2.1. Combine Bathrooms and Bedrooms\n",
        "# Create a new feature representing the total number of rooms (bedrooms + bathrooms)\n",
        "#df2['totalRooms'] = df2['numBedrooms'] + df2['numBathrooms']\n",
        "\n",
        "# 3. Split Data into Training and Testing Sets\n",
        "X = df2.drop('listPrice', axis=1)\n",
        "y = df2['listPrice']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Model Selection and Training\n",
        "# Try different models: Linear Regression, Ridge, Lasso, ElasticNet, Decision Tree, Random Forest, Gradient Boosting\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge': Ridge(),\n",
        "    'Lasso': Lasso(),\n",
        "    'ElasticNet': ElasticNet(),\n",
        "    'Decision Tree': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor()\n",
        "}\n",
        "\n",
        "# 5. Hyperparameter Tuning\n",
        "# Use GridSearchCV or RandomizedSearchCV to find the best hyperparameters for each model\n",
        "param_grids = {\n",
        "    'Ridge': {'alpha': np.logspace(-3, 3, 7)},\n",
        "    'Lasso': {'alpha': np.logspace(-3, 3, 7)},\n",
        "    'ElasticNet': {'alpha': np.logspace(-3, 3, 7), 'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
        "    'Decision Tree': {'max_depth': [None, 5, 10, 20], 'min_samples_split': [2, 5, 10]},\n",
        "    'Random Forest': {'n_estimators': [100, 200, 500], 'max_depth': [None, 5, 10, 30]},\n",
        "    'Gradient Boosting': {'n_estimators': [100, 200, 500], 'learning_rate': [0.01, 0.1, 1]}\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "for name, model in models.items():\n",
        "    if name in param_grids:\n",
        "        grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='neg_mean_squared_error')\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_models[name] = grid_search.best_estimator_\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        best_models[name] = model\n",
        "\n",
        "# 6. Model Evaluation\n",
        "# Evaluate the best models using metrics like MSE, R-squared, MAE, RMSE\n",
        "for name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f'Model: {name}')\n",
        "    print(f'MSE: {mean_squared_error(y_test, y_pred)}')\n",
        "    print(f'R-squared: {r2_score(y_test, y_pred)}')\n",
        "    print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
        "    print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}')\n",
        "    print('---')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RQYQpBxVzPf",
        "outputId": "c573a944-8fb4-454e-e658-49abb3a610c9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+14, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.579e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.521e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+14, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+14, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.938e+13, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.758e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.905e+12, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+13, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.355e+11, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.529e+12, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.790e+11, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.351e+12, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.968e+12, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.385e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.463e+11, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.279e+12, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.201e+13, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.735e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.368e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e+13, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.745e+13, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.198e+14, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.667e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.569e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.913e+13, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+14, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+14, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.579e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.521e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+14, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+14, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.396e+13, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.060e+12, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.938e+13, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.758e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.905e+12, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+13, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.355e+11, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.529e+12, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.790e+11, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.351e+12, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Linear Regression\n",
            "MSE: 360984210831.97687\n",
            "R-squared: 0.5382041449232218\n",
            "MAE: 318846.9139129704\n",
            "RMSE: 600819.6158848152\n",
            "---\n",
            "Model: Ridge\n",
            "MSE: 361117559007.5886\n",
            "R-squared: 0.5380335567563941\n",
            "MAE: 318462.3690486643\n",
            "RMSE: 600930.5775275449\n",
            "---\n",
            "Model: Lasso\n",
            "MSE: 361007036596.21954\n",
            "R-squared: 0.5381749446341235\n",
            "MAE: 318795.06755325524\n",
            "RMSE: 600838.6111063599\n",
            "---\n",
            "Model: ElasticNet\n",
            "MSE: 361007036596.21954\n",
            "R-squared: 0.5381749446341235\n",
            "MAE: 318795.06755325524\n",
            "RMSE: 600838.6111063599\n",
            "---\n",
            "Model: Decision Tree\n",
            "MSE: 321833265109.8047\n",
            "R-squared: 0.5882887301053987\n",
            "MAE: 264060.7491090316\n",
            "RMSE: 567303.5035232946\n",
            "---\n",
            "Model: Random Forest\n",
            "MSE: 163867143514.01767\n",
            "R-squared: 0.7903698683007838\n",
            "MAE: 195897.30471856656\n",
            "RMSE: 404805.06853795407\n",
            "---\n",
            "Model: Gradient Boosting\n",
            "MSE: 140674210959.14993\n",
            "R-squared: 0.8200398643824087\n",
            "MAE: 205034.9004252538\n",
            "RMSE: 375065.6088728343\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f'Model: {name}')\n",
        "    print(f'MSE: {mean_squared_error(y_test, y_pred)}')\n",
        "    print(f'R-squared: {r2_score(y_test, y_pred)}')\n",
        "    print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
        "    print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}')\n",
        "    print(f'%Error: { abs(sum(y_test) - sum(y_pred))/sum(y_test) * 100 }%')\n",
        "    print('---')"
      ],
      "metadata": {
        "id": "OzP3OWGRjSTT",
        "outputId": "2dbe35b6-1d75-4bde-e9c6-dfc992d860b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Linear Regression\n",
            "MSE: 360984210831.97687\n",
            "R-squared: 0.5382041449232218\n",
            "MAE: 318846.9139129704\n",
            "RMSE: 600819.6158848152\n",
            "%Error: 2.083551431030492%\n",
            "---\n",
            "Model: Ridge\n",
            "MSE: 361117559007.5886\n",
            "R-squared: 0.5380335567563941\n",
            "MAE: 318462.3690486643\n",
            "RMSE: 600930.5775275449\n",
            "%Error: 2.085230854572631%\n",
            "---\n",
            "Model: Lasso\n",
            "MSE: 361007036596.21954\n",
            "R-squared: 0.5381749446341235\n",
            "MAE: 318795.06755325524\n",
            "RMSE: 600838.6111063599\n",
            "%Error: 2.0837174558447416%\n",
            "---\n",
            "Model: ElasticNet\n",
            "MSE: 361007036596.21954\n",
            "R-squared: 0.5381749446341235\n",
            "MAE: 318795.06755325524\n",
            "RMSE: 600838.6111063599\n",
            "%Error: 2.0837174558447416%\n",
            "---\n",
            "Model: Decision Tree\n",
            "MSE: 321833265109.8047\n",
            "R-squared: 0.5882887301053987\n",
            "MAE: 264060.7491090316\n",
            "RMSE: 567303.5035232946\n",
            "%Error: 3.3720597146635645%\n",
            "---\n",
            "Model: Random Forest\n",
            "MSE: 163867143514.01767\n",
            "R-squared: 0.7903698683007838\n",
            "MAE: 195897.30471856656\n",
            "RMSE: 404805.06853795407\n",
            "%Error: 1.9385095302746285%\n",
            "---\n",
            "Model: Gradient Boosting\n",
            "MSE: 140674210959.14993\n",
            "R-squared: 0.8200398643824087\n",
            "MAE: 205034.9004252538\n",
            "RMSE: 375065.6088728343\n",
            "%Error: 1.0647098945480342%\n",
            "---\n"
          ]
        }
      ]
    }
  ]
}
