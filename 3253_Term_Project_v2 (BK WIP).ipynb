{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYrMCWo5k0llZIub67vJSv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahaansshah/3253-083_Group9/blob/main/3253_Term_Project_v2%20(BK%20WIP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-geohash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMj27sqCeKLG",
        "outputId": "4c6e7fc5-e40c-4561-b1ea-21365e541cd3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-geohash in /usr/local/lib/python3.10/dist-packages (0.8.5)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from geohash import encode\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "# Assuming you have the JSON data in a file named 'data.json' in your Google Drive\n",
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the path to your JSON file\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/3253/ontario_housing_cleaned.json'\n",
        "\n",
        "# Load the JSON data from the file line by line\n",
        "records = []\n",
        "with open(file_path, 'r') as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            data = json.loads(line) # Load each line as a separate JSON object\n",
        "            record = data.get('data') # Use .get() to handle potential missing 'data' key\n",
        "            if record is not None: # Check if 'data' exists and is not None\n",
        "                features = {}\n",
        "                for feature_group in record.get('features', []): # Handle cases where 'features' might be missing\n",
        "                    for feature_category in feature_group.get('value', []):\n",
        "                        for feature in feature_category.get('value', []):\n",
        "                            features[f\"{feature_group['name']}_{feature_category['name']}_{feature['name']}\"] = feature['value']\n",
        "\n",
        "                record.update(features)  # Add the extracted features to the record\n",
        "                record.pop('features', None)  # Remove the original nested features structure if it exists\n",
        "                records.append(record)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Skipping invalid JSON line: {line}\") # Log any lines that fail to parse\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "#df.to_csv('/content/drive/MyDrive/Colab Notebooks/3253/ontario_housing_cleaned.csv', index=False)\n",
        "\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head())"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D0yBVG0_bKG",
        "outputId": "8f42d3c2-d460-43ca-c124-05f79694909f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                         address subPremise  \\\n",
            "0  2480 Prince Michael Dr S #210       #210   \n",
            "1                 1176 Grange Rd              \n",
            "2                 3511 Post Road              \n",
            "3            95 Dundas St W #513       #513   \n",
            "4          3137 William Rose Way              \n",
            "\n",
            "                                         fullAddress       division      city  \\\n",
            "0  2480 Prince Michael Dr S #210 Oakville, ON L6H...  Halton Region  Oakville   \n",
            "1                1176 Grange Rd Oakville, ON L6H 1P6  Halton Region  Oakville   \n",
            "2                3511 Post Road Oakville, ON L6H 7W5                 Oakville   \n",
            "3           95 Dundas St W #513 Oakville, ON L6M 5N4  Halton Region  Oakville   \n",
            "4         3137 William Rose Way Oakville, ON L6H 0T1  Halton Region  Oakville   \n",
            "\n",
            "   cityCode closePrice closeDate daysOnMovoto  daysOnMovotoRaw  ... is3DTour  \\\n",
            "0    2506.0       None      None      14 days               14  ...      NaN   \n",
            "1    2506.0       None      None  Just Listed                0  ...      NaN   \n",
            "2       NaN       None      None       6 days                6  ...      NaN   \n",
            "3    2506.0       None      None      34 days               34  ...      NaN   \n",
            "4    2506.0       None      None      76 days               76  ...     True   \n",
            "\n",
            "  isPriceUp priceChangeRaw priceChange priceChangeFriendlyPrice  \\\n",
            "0       NaN            NaN         NaN                      NaN   \n",
            "1       NaN            NaN         NaN                      NaN   \n",
            "2       NaN            NaN         NaN                      NaN   \n",
            "3       NaN            NaN         NaN                      NaN   \n",
            "4       NaN            NaN         NaN                      NaN   \n",
            "\n",
            "   lastListPriceRaw lastListPrice pricePerAcre pricePerAcreRaw  \\\n",
            "0               NaN           NaN          NaN             NaN   \n",
            "1               NaN           NaN          NaN             NaN   \n",
            "2               NaN           NaN          NaN             NaN   \n",
            "3               NaN           NaN          NaN             NaN   \n",
            "4               NaN           NaN          NaN             NaN   \n",
            "\n",
            "  pricePerAcreIntRaw  \n",
            "0                NaN  \n",
            "1                NaN  \n",
            "2                NaN  \n",
            "3                NaN  \n",
            "4                NaN  \n",
            "\n",
            "[5 rows x 200 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the specified columns\n",
        "# These features are either irrelevant for predicting price, redundant, or contain mostly null values.\n",
        "columns_to_drop = ['tnImgPath', 'imagesURL', 'photos', 'id', 'listingCoAgent', 'listingAgent',\n",
        "                   'listingAgentLicense', 'listingOfficePhone',\n",
        "                   'mlsDbNumber', 'mlsSysid', 'mls', 'mlsNumber', 'openHouses',\n",
        "                   'officeColistName', 'officeListName', 'officeListPhone', 'photoCount', 'price', 'priceSeo', 'propertyTypeValue', 'propertyTypeDisplayName'\n",
        "                   'state', 'status', 'pageUrlWithoutDomain', 'houseRealStatus', 'listingOfficeDescription', 'hoafee', 'hoafeeRaw', 'dppInactiveOnActive',\n",
        "                   'dppInactive', 'priceChanged', 'priceChangedDate', 'updatedTime', 'hiddenByComplianceRule', 'dateHidden', 'propertyId', 'visibility',\n",
        "                   'permitAvm', 'modificationTimestamp', 'createdAt', 'propertyDateHidden', 'imageDownloaderStatus', 'onMarketDateTime', 'priceChangeAmount', 'thumbnail',\n",
        "                   'photoCount1', 'virtualTourLink', 'fsa', 'dppurl', 'listingByMovoto', 'labelDisplayName', 'listingPriceFormat', 'comparableHomes',\n",
        "                   'listDateLLFormat', 'listDateLLFormat', 'listDateFormat', 'listDateUTC', 'pricePerSqft', 'pricePerSqftRaw', 'pricePerSqftIntRaw', 'isFavorite',\n",
        "                   'petiteImagePath', 'propertyTypeNameUrl', 'closePrice', 'closeDate', 'daysOnMovoto', 'cityCode', 'listDate',\n",
        "                   'state', 'soldDate', 'isHotHome', 'isSold', 'isPriceReduced', 'label', 'labelclass', 'Amenities  Utilities_Other_Pets Allowed (YN)',\n",
        "                   'Amenities  Utilities_Utility_Utilities', 'Exterior_Building_# Total Stories', 'Exterior_Building_Building Amenities',\n",
        "                   'Exterior_Building_Building Amenities', 'Exterior_Other_Exterior Features', 'Exterior_Other_Fencing', 'Exterior_Building_Foundation',\n",
        "                   'Exterior_Parking_# Garage Spaces', 'Exterior_Parking_Drive', 'Exterior_Parking_Garage Features', 'Exterior_Parking_Has Basement (YN)',\n",
        "                   'Exterior_Parking_Has Garage (YN)', 'Exterior_Parking_Parking Desc', 'Exterior_Parking_Parking Spot #',\n",
        "                   'Interior_Bathrooms_# Full Baths', 'Interior_Bathrooms_# Half Baths', 'Interior_Bathrooms_# Three-Quarter', 'Interior_Bathrooms_# Total Bathrooms',\n",
        "                   'Interior_Bedrooms_Family Room Available', 'Interior_Flooring_Flooring', 'Interior_Interior_Appliances', 'Interior_Interior_Has Fireplace (YN)',\n",
        "                   'Interior_Interior_Laundry Information', 'Interior_Other_Interior Features', 'Location_Community_Community', 'Location_Community_Community Features',\n",
        "                   'Location_Community_County', 'Location_Location features_Area', 'Location_Location features_Subdivision', 'Location_Location features_View',\n",
        "                   'Location_Location features_Water Body Name', 'Location_Location features_Water Body Type', 'Location_Location features_Water Source',\n",
        "                   'Location_Location features_Zoning Description', 'Location_Other_Directions', 'Location_Schools_Elementary School', 'Location_Schools_High School',\n",
        "                   'Location_Schools_Middle School', 'Location_Schools_School District', 'Lot Land Details_Lot Information_Exposure',\n",
        "                   'Lot Land Details_Lot Information_FarmAgriculture', 'Lot Land Details_Lot Information_Lot Desc', 'Lot Land Details_Lot Information_Lot Size Units',\n",
        "                   'Lot Land Details_Lot Information_Water Features', 'Lot Land Details_Lot Information_Water Frontage', 'Overview_Lot_Approx Lot Size (Range)',\n",
        "                   'Overview_Other_Approx Age', 'Overview_Other_Is Gated Community (YN)', 'Overview_Other_Is Horse Property (YN)', 'Overview_Other_New Construction (YN)',\n",
        "                   'Overview_Other_Year Built', 'Overview_Other_HOA', 'Overview_Property_Approx Square Feet (Range)', 'Overview_Property_MLS #',\n",
        "                   'Overview_Property_Status', 'Overview_Property_Storage Unit (Locker)', 'Overview_Property_Virtual Tour', 'Overview_Taxes_Tax Year', 'Overview_Taxes_Taxes',\n",
        "                   'Rooms_Rooms Information_Movotorooms', 'SOA_HOUSEKEEPING_ATTRS_LISTING_SOURCE_URL_Listing Source URL',\n",
        "                   'SOA_HOUSEKEEPING_ATTRS_LISTING_TYPE_Listing Type Identifier', 'virtualLink', 'is3DTour', 'isPriceUp', 'priceChange', 'priceChangeFriendlyPrice',\n",
        "                   'lastListPriceRaw', 'lastListPrice', 'pricePerAcre', 'pricePerAcreRaw', 'pricePerAcreIntRaw', 'subPremise', 'fullAddress', 'division', 'daysOnMovotoRaw',\n",
        "                   'description', 'lotSizeRaw', 'sqftTotalRaw', 'neighborhoodN', 'numBathroomsRaw', 'numBedroomsRaw', 'priceRaw', 'propertyTypeName','propertyTypeDisplayName',\n",
        "                   'yearBuiltRaw', 'totalMonthlyFee', 'neighborhoodNGeoId', 'isVOWListing', 'addressRaw', 'address2', 'lotSizeUnit', 'sqftTotalUnit',\n",
        "                   'Amenities  Utilities_Utility_Sewer Septic', 'Amenities  Utilities_Heating  Cooling_Heat Type', 'Amenities  Utilities_Other_Has Pool (YN)',\n",
        "                   'Amenities  Utilities_Utility_Utility_Sewer Septic', 'Exterior_Building_Construction Materials', 'Exterior_Building_Roof',\n",
        "                   'Exterior_Other_Other Structures', 'Exterior_Parking_# Parking Spaces', 'Interior_Bathrooms_# Three-Quarter Baths',\n",
        "                   'Interior_Bedrooms_# of Above Grade Bedrooms', 'Interior_Bedrooms_# of Below Grade Bedrooms', 'Interior_Bedrooms_# of Rooms',\n",
        "                   'Interior_More rooms_# of Kitchens', 'Lot Land Details_Lot Information_Lot Dimensions', 'Overview_Lot_Lot Size (Acres)', 'Overview_Other_Maintenance Fee',\n",
        "                   'Overview_Property_Basement Information', 'Overview_Property_Building Size ', 'Overview_Property_Property Sub Type',\n",
        "                   'city', 'neighborhoodName', 'priceChangeRaw', 'address', 'zipCode']\n",
        "# Use errors='ignore' to avoid errors if a column doesn't exist, drop in-place\n",
        "df.drop(columns=columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/3253/ontario_housing_cleaned2.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wXTkKiXTAzru"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the DataFrame\n",
        "#print(df.head(30).to_string())"
      ],
      "metadata": {
        "id": "z3DrxEZ3fOwQ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.copy()\n",
        "\n",
        "#print(df2.head(30).to_string())\n",
        "\n",
        "\n",
        "## Create Geohash Feature\n",
        "#df2['geohash'] = df2.apply(lambda row: encode(row['latitude'], row['longitude'], precision=6), axis=1)\n",
        "#df2.drop(columns=['latitude', 'longitude'], inplace=True, errors='ignore')\n",
        "\n",
        "## Drop Rows with Missing 'listPrice', and show how many were dropped\n",
        "print(f\"Number of rows with missing 'listPrice': {df2['listPrice'].isna().sum()}\")\n",
        "df2.dropna(subset=['listPrice'], inplace=True)\n",
        "\n",
        "# Drop outliers that will add noise to the model, not going to predict for outliers\n",
        "# Drop propertyType in 'FARM', 'Land', 'Other', 'Multi Family'\n",
        "df2 = df2[~df2['propertyType'].isin(['FARM', 'Land', 'Other', 'Multi_Family'])]\n",
        "# Drop garage greater than 4\n",
        "###df2 = df2[df2['garage'] <= 4]\n",
        "\n",
        "# Fix column names\n",
        "df2.columns = df2.columns.str.replace(r' +', '_', regex=True)\n",
        "\n",
        "# Categorical variables levels cleanup\n",
        "df2['Amenities_Utilities_Heating_Cooling_Cooling'] = df2['Amenities_Utilities_Heating_Cooling_Cooling'].str.replace(r'Ductless.*|.*Central .*', 'Y', regex=True)\n",
        "df2['Amenities_Utilities_Heating_Cooling_Cooling'] = df2['Amenities_Utilities_Heating_Cooling_Cooling'].str.replace(r'^(?!.*Y).*', 'N', regex=True)\n",
        "df2['Amenities_Utilities_Heating_Cooling_Heat_Source'] = df2['Amenities_Utilities_Heating_Cooling_Heat_Source'].str.replace(r'Electric.*', 'Electric', regex=True)\n",
        "df2['Amenities_Utilities_Heating_Cooling_Heat_Source'] = df2['Amenities_Utilities_Heating_Cooling_Heat_Source'].str.replace(r'Natural gas.*', 'Gas', regex=True)\n",
        "df2['Amenities_Utilities_Heating_Cooling_Heat_Source'] = df2['Amenities_Utilities_Heating_Cooling_Heat_Source'].str.replace(r'^(?!Electric|Gas).*', 'Other', regex=True)\n",
        "\n",
        "\n",
        "## 1.6. One-Hot Encode Categorical Features\n",
        "# One-hot encode categorical features: 'city', 'neighborhoodName', 'propertyType', 'parking', 'garage', 'Amenities  Utilities_Heating  Cooling_Cooling', 'Amenities  Utilities_Heating  Cooling_Heat Type'\n",
        "categorical_features = ['propertyType', 'Amenities_Utilities_Heating_Cooling_Cooling', 'Amenities_Utilities_Heating_Cooling_Heat_Source']\n",
        "df2 = pd.get_dummies(df2, columns=categorical_features, drop_first=True)*1\n",
        "\n",
        "# Fix column names (because of values and their one-hot encoding)\n",
        "df2.columns = df2.columns.str.replace(r' +', '_', regex=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Impute Missing Values\n",
        "\n",
        "# Impute missing year built with the median year built for the property type\n",
        "#df2['yearBuilt'] = df2.groupby('propertyType')['yearBuilt'].transform(lambda x: x.fillna(x.median()))\n",
        "# replace all non-numeric values in column df2[['yearBuilt']] with Nan\n",
        "df2['yearBuilt'] = pd.to_numeric(df2['yearBuilt'], errors='coerce')\n",
        "df2['numBedrooms'] = pd.to_numeric(df2['numBedrooms'], errors='coerce')\n",
        "df2['numBathrooms'] = pd.to_numeric(df2['numBathrooms'], errors='coerce')\n",
        "df2['lotSize'] = pd.to_numeric(df2['lotSize'], errors='coerce')\n",
        "df2['sqftTotal'] = pd.to_numeric(df2['sqftTotal'], errors='coerce')\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = ['yearBuilt', 'latitude', 'longitude', 'numBedrooms', 'numBathrooms', 'lotSize', 'parking', 'sqftTotal', 'garage']\n",
        "df2[numerical_features] = scaler.fit_transform(df2[numerical_features])\n",
        "\n",
        "# Impute yearBuilt using KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "# Scale yearBuilt for KNNImputer\n",
        "df2['yearBuilt'] = imputer.fit_transform(df2[['yearBuilt', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'latitude', 'longitude']])\n",
        "\n",
        "# Impute missing lot size based on median lot size for similar properties (same property type, city, and number of bedrooms)\n",
        "#df2['lotSize'] = df2.groupby(['propertyType', 'numBedrooms', 'numBathrooms'])['lotSize'].transform(lambda x: x.fillna(x.median()))\n",
        "# Impute lotSize based on numBedrooms and numBathrooms using KNNImputer\n",
        "\n",
        "#imputer = KNNImputer(n_neighbors=5)\n",
        "df2['lotSize'] = imputer.fit_transform(df2[['lotSize', 'numBedrooms', 'numBathrooms', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'parking']])\n",
        "\n",
        "# Similar imputation strategy as 'lotSize'\n",
        "#df2['sqftTotal'] = df2.groupby(['propertyType', 'numBedrooms', 'numBathrooms'])['sqftTotal'].transform(lambda x: x.fillna(x.median()))\n",
        "\n",
        "#imputer = KNNImputer(n_neighbors=5)\n",
        "df2['sqftTotal'] = imputer.fit_transform(df2[['sqftTotal', 'numBedrooms', 'numBathrooms', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'parking']])\n",
        "\n",
        "#imputer = KNNImputer(n_neighbors=5)\n",
        "df2['garage'] = imputer.fit_transform(df2[['garage', 'numBedrooms', 'numBathrooms', 'propertyType_Single_Family', 'propertyType_TOWNHOUSE', 'parking']])\n",
        "\n",
        "\n",
        "# drop all rows that have NaN in any column\n",
        "columns_to_check = ['garage', 'parking', 'numBedrooms', 'numBathrooms']\n",
        "df2.dropna(subset=columns_to_check, inplace=True)\n",
        "\n",
        "#print(df2[[]].isna().sum())\n",
        "print(df2.head(30).to_string())\n",
        "#print(df2.to_string())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G98OC-Y4PfzV",
        "outputId": "64fe3f36-69aa-4cab-85f4-8777d2bf0d1b"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with missing 'listPrice': 0\n",
            "    latitude  listPrice  longitude   lotSize  sqftTotal  numBathrooms  numBedrooms   parking  yearBuilt    garage  propertyType_Multi_Family  propertyType_Single_Family  propertyType_TOWNHOUSE  Amenities_Utilities_Heating_Cooling_Cooling_Y  Amenities_Utilities_Heating_Cooling_Heat_Source_Gas  Amenities_Utilities_Heating_Cooling_Heat_Source_Other\n",
            "0   0.984358     995000   0.010590  0.007382   0.916550      0.028571     0.022222  0.045455   0.928000  0.026316                          0                           1                       0                                              1                                                    1                                                      0\n",
            "1   0.983963    1190000   0.010911  0.007382   0.914343      0.028571     0.044444  0.068182   0.869333  0.026316                          0                           1                       0                                              1                                                    0                                                      1\n",
            "2   0.984293    1450000   0.010157  0.424847   0.936610      0.114286     0.088889  0.045455   0.968889  0.026316                          0                           0                       1                                              1                                                    1                                                      0\n",
            "3   0.983900     579900   0.010284  0.362211   0.600802      0.000000     0.000000  0.022727   0.986667  0.026316                          0                           0                       0                                              1                                                    0                                                      1\n",
            "4   0.984331    2799900   0.010447  0.007382   0.776128      0.142857     0.088889  0.090909   0.968889  0.052632                          0                           1                       0                                              1                                                    0                                                      1\n",
            "5   0.982861    1585000   0.009904  0.007437   0.755065      0.057143     0.066667  0.159091   0.902222  0.052632                          0                           1                       0                                              1                                                    0                                                      1\n",
            "6   0.983793     579900   0.010899  0.007382   0.787763      0.000000     0.044444  0.022727   0.821333  0.005263                          0                           1                       0                                              0                                                    0                                                      0\n",
            "7   0.982757    1149777   0.010122  0.424847   0.910732      0.057143     0.044444  0.090909   0.848889  0.026316                          0                           0                       1                                              1                                                    0                                                      1\n",
            "8   0.981806    2050000   0.010317  0.007382   0.776128      0.114286     0.111111  0.090909   0.873778  0.052632                          0                           1                       0                                              1                                                    1                                                      0\n",
            "9   0.982932     599000   0.009761  0.362167   0.592979      0.000000     0.000000  0.000000   0.880889  0.052632                          0                           0                       0                                              1                                                    0                                                      1\n",
            "10  0.983556    1485000   0.010708  0.007382   0.755065      0.057143     0.066667  0.113636   0.728889  0.026316                          0                           1                       0                                              1                                                    0                                                      1\n",
            "11  0.983518    3099000   0.011190  0.000169   0.753661      0.057143     0.044444  0.181818   0.693333  0.052632                          0                           1                       0                                              1                                                    0                                                      1\n",
            "12  0.982963     769000   0.009778  0.007382   0.919157      0.028571     0.044444  0.022727   0.909333  0.026316                          0                           1                       0                                              1                                                    1                                                      0\n",
            "13  0.983868    1980000   0.010122  0.007382   0.776128      0.114286     0.088889  0.090909   0.941333  0.052632                          0                           1                       0                                              1                                                    1                                                      0\n",
            "14  0.983961     675000   0.010368  0.007382   0.919157      0.028571     0.022222  0.022727   0.951111  0.015789                          0                           1                       0                                              1                                                    1                                                      0\n",
            "15  0.982823    1689000   0.010784  0.007437   0.755065      0.057143     0.066667  0.159091   0.857778  0.026316                          0                           1                       0                                              1                                                    0                                                      1\n",
            "16  0.983360    4598000   0.011196  0.007382   0.755065      0.085714     0.044444  0.136364   0.875556  0.052632                          0                           1                       0                                              1                                                    0                                                      1\n",
            "17  0.984267    1875000   0.010477  0.007382   0.776128      0.085714     0.066667  0.090909   0.947556  0.073684                          0                           1                       0                                              1                                                    1                                                      0\n",
            "18  0.983902    2299900   0.010706  0.007382   0.755065      0.085714     0.088889  0.136364   0.877333  0.052632                          0                           1                       0                                              1                                                    1                                                      0\n",
            "19  0.983817     915000   0.010199  0.424847   0.910732      0.057143     0.022222  0.045455   0.958222  0.026316                          0                           0                       1                                              1                                                    0                                                      1\n",
            "20  0.982906     499000   0.010339  0.007382   0.765296      0.000000     0.022222  0.022727   0.851556  0.010526                          0                           1                       0                                              0                                                    0                                                      0\n",
            "21  0.981784    2367000   0.010345  0.007382   0.776128      0.085714     0.066667  0.090909   0.873778  0.052632                          0                           1                       0                                              1                                                    0                                                      1\n",
            "22  0.982867    3770000   0.010666  0.007333   0.755065      0.142857     0.088889  0.136364   0.864000  0.052632                          0                           1                       0                                              1                                                    0                                                      1\n",
            "23  0.983269    1089000   0.010234  0.362167   0.858977      0.028571     0.044444  0.022727   0.968889  0.026316                          0                           0                       0                                              1                                                    1                                                      0\n",
            "24  0.983340    1499000   0.010884  0.007382   0.916550      0.028571     0.022222  0.045455   0.893333  0.026316                          0                           1                       0                                              1                                                    0                                                      1\n",
            "25  0.983225    1899900   0.010040  0.007382   0.776128      0.085714     0.111111  0.090909   0.888000  0.052632                          0                           1                       0                                              1                                                    1                                                      0\n",
            "26  0.983680    1699999   0.010323  0.007382   0.776128      0.085714     0.133333  0.090909   0.908444  0.052632                          0                           1                       0                                              1                                                    1                                                      0\n",
            "27  0.983950     679000   0.010365  0.424847   0.951856      0.028571     0.022222  0.022727   0.946667  0.026316                          0                           0                       1                                              1                                                    0                                                      1\n",
            "28  0.000000     999000   1.000000  0.424847   0.912136      0.057143     0.066667  0.022727   0.887111  0.026316                          0                           0                       1                                              1                                                    1                                                      0\n",
            "29  0.983230    1649000   0.010076  0.007382   0.776128      0.085714     0.066667  0.090909   0.888000  0.073684                          0                           1                       0                                              1                                                    1                                                      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ## 1.7. Handle Outliers\n",
        "# # Identify outliers in 'listPrice' based on IQR and remove them\n",
        "# Q1 = df2['listPrice'].quantile(0.25)\n",
        "# Q3 = df2['listPrice'].quantile(0.75)\n",
        "# IQR = Q3 - Q1\n",
        "# upper_bound = Q3 + 1.5 * IQR\n",
        "# lower_bound = Q1 - 1.5 * IQR\n",
        "# df2 = df2[(df2['listPrice'] >= lower_bound) & (df2['listPrice'] <= upper_bound)]\n",
        "\n",
        "# 2. Feature Engineering\n",
        "\n",
        "## 2.1. Combine Bathrooms and Bedrooms\n",
        "# Create a new feature representing the total number of rooms (bedrooms + bathrooms)\n",
        "#df2['totalRooms'] = df2['numBedrooms'] + df2['numBathrooms']\n",
        "\n",
        "# 3. Split Data into Training and Testing Sets\n",
        "X = df2.drop('listPrice', axis=1)\n",
        "y = df2['listPrice']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Model Selection and Training\n",
        "# Try different models: Linear Regression, Ridge, Lasso, ElasticNet, Decision Tree, Random Forest, Gradient Boosting\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge': Ridge(),\n",
        "    'Lasso': Lasso(),\n",
        "    'ElasticNet': ElasticNet(),\n",
        "    'Decision Tree': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor()\n",
        "}\n",
        "\n",
        "# 5. Hyperparameter Tuning\n",
        "# Use GridSearchCV or RandomizedSearchCV to find the best hyperparameters for each model\n",
        "param_grids = {\n",
        "    'Ridge': {'alpha': np.logspace(-3, 3, 7)},\n",
        "    'Lasso': {'alpha': np.logspace(-3, 3, 7)},\n",
        "    'ElasticNet': {'alpha': np.logspace(-3, 3, 7), 'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
        "    'Decision Tree': {'max_depth': [None, 5, 10, 20], 'min_samples_split': [2, 5, 10]},\n",
        "    'Random Forest': {'n_estimators': [100, 200, 500], 'max_depth': [None, 5, 10]},\n",
        "    'Gradient Boosting': {'n_estimators': [100, 200, 500], 'learning_rate': [0.01, 0.1, 1]}\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "for name, model in models.items():\n",
        "    if name in param_grids:\n",
        "        grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='neg_mean_squared_error')\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_models[name] = grid_search.best_estimator_\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        best_models[name] = model\n",
        "\n",
        "# 6. Model Evaluation\n",
        "# Evaluate the best models using metrics like MSE, R-squared, MAE, RMSE\n",
        "for name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f'Model: {name}')\n",
        "    print(f'MSE: {mean_squared_error(y_test, y_pred)}')\n",
        "    print(f'R-squared: {r2_score(y_test, y_pred)}')\n",
        "    print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
        "    print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}')\n",
        "    print('---')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RQYQpBxVzPf",
        "outputId": "743f12fe-a288-4822-e748-20a98ed0ebf8"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e+14, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.927e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.951e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+14, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.571e+14, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.210e+13, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.806e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.387e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.818e+12, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+13, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.440e+11, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.477e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.897e+13, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e+11, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.640e+12, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e+12, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.077e+12, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.727e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.490e+11, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e+12, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.667e+13, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.116e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.827e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e+13, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+13, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.414e+14, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.025e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.100e+13, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+14, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e+14, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.927e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.951e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+14, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.571e+14, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.667e+13, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.852e+12, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.210e+13, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.806e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.387e+14, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.818e+12, tolerance: 1.271e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+13, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.440e+11, tolerance: 1.456e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.477e+14, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.897e+13, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e+11, tolerance: 1.364e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.640e+12, tolerance: 1.397e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e+12, tolerance: 1.426e+11\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Linear Regression\n",
            "MSE: 453016274382.0671\n",
            "R-squared: 0.4204703931238216\n",
            "MAE: 354746.0576628946\n",
            "RMSE: 673064.8366851942\n",
            "---\n",
            "Model: Ridge\n",
            "MSE: 453164212655.0247\n",
            "R-squared: 0.42028114029998864\n",
            "MAE: 354284.44247689436\n",
            "RMSE: 673174.7266906451\n",
            "---\n",
            "Model: Lasso\n",
            "MSE: 452660225641.15564\n",
            "R-squared: 0.4209258751859851\n",
            "MAE: 354229.3434633549\n",
            "RMSE: 672800.2865941391\n",
            "---\n",
            "Model: ElasticNet\n",
            "MSE: 452660225641.15564\n",
            "R-squared: 0.4209258751859851\n",
            "MAE: 354229.3434633549\n",
            "RMSE: 672800.2865941391\n",
            "---\n",
            "Model: Decision Tree\n",
            "MSE: 272054630333.89877\n",
            "R-squared: 0.651968986806692\n",
            "MAE: 243943.7074293451\n",
            "RMSE: 521588.56422845274\n",
            "---\n",
            "Model: Random Forest\n",
            "MSE: 165728990423.98447\n",
            "R-squared: 0.787988065551493\n",
            "MAE: 204652.19100001908\n",
            "RMSE: 407098.2564737713\n",
            "---\n",
            "Model: Gradient Boosting\n",
            "MSE: 144060492686.33475\n",
            "R-squared: 0.8157078996625887\n",
            "MAE: 208379.70969156295\n",
            "RMSE: 379553.01696381596\n",
            "---\n"
          ]
        }
      ]
    }
  ]
}